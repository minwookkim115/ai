{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Segmentation-models"]},{"cell_type":"markdown","metadata":{},"source":["### Multi-class Segmentation\n","- 이미지 픽셀 당 한 번의 분류를 수행\n","    - 한 픽셀 자리에서 Softmax를 통해 여러 장의 segmentation map 중 대표적인 값을 선택\n","    - 픽셀 당 클래스가 상호 배타적임\n","- 한 픽셀은 무조건 하나의 카테고리로만 분류\n","- 마스크가 겹치지 않음\n","- 최종적인 마스크는 (1, H, W)로 축약할 수 있음\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBhPDc%2FbtrFUM91Xaa%2FWT9ysDK2jkQmlqZeCdkL11%2Fimg.png)"]},{"cell_type":"markdown","metadata":{},"source":["### Multi-label Segmentation\n","- 이미지 픽셀 당 Class_num 번 분류를 수행\n","    - 한 Segmentation map은 다른 map과 공존할 수 있음\n","    - 각 픽셀은 총 Class_num 만큼의 sigmoid 계산을 통해 해당  클래스 종속 여부를 판별함\n","- 한 픽셀은 여러 개의 클래스에 속할 수 있음\n","- 마스크가 동일 영역에 겹칠 수 있음\n","- 최종적인 마스크를 (1, H, W) 형태로 축약할 수 없고, 반드시 (1, C, H, W) 형태만 사용해야 함\n","![](https://www.kaggleusercontent.com/kf/19102645/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..RRX-XNJRBAcyAZqEPOcioQ.PmKGfJfwxu3mLzv8eUF3uPrql0VmRsROtUHCXpDueeOOewVe0NK0KZBiXIYri7l8LM85BXjPOCN29IwHnWEnXVdkMYRiO5bOv2lGZgV7QWr1SOh_LLbmXgR22TRIuJzTLP_yiDjScB41IuPCcJG_u-aICAswNWzmCTj1VMSkbUJzek_LBcJB26u_RohkqxRPFZiBWVYdtHqk1MI15lEZGDAqbF3V6D4_olW7Y2kf0L_KMzWJvKxrEI9zrbz48-0qOBJ_q95goVhZWjA_hDL-qm6TIcqOd4cNbhC8H6M_55qwsojFp0_1nAhmxgrPLFYwF1yFAyVTca2YWvqJYHuwfsBhNKFEB36wtXwrFnmQWDrWL9beVN-S9iIzl-Mf5xtf6fQFu1f-Z4pQbKstbXGkgYdGyoxhiW7FR0JMWyBjGB83IIsyFjmpXCDrLvJqOI99GeA8bxNx1_Ziv7_9Qmfs_nMrLdK2TWpgwLAScPxyS17OQzKULPclyqZmQONQaLilxIm4XORZ8M0l0XzFCNj9q5-zdUSOws7DdPtAxWgvIGrL44qcf4saBJTP9xbh_poHNkXNehpJNWCR0dlbN5bTuzDBbagXusCTqkzO5uI6xDTq-OyfqXl-4X--CiHgv-Ms4O9n0sEIlpQ4_jZOql8jfQ.mr8-HbQWAUOJd_HyFP8Xgw/__results___files/__results___23_9.png)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:56:05.631900Z","iopub.status.busy":"2024-09-23T08:56:05.631122Z","iopub.status.idle":"2024-09-23T08:56:26.378785Z","shell.execute_reply":"2024-09-23T08:56:26.377510Z","shell.execute_reply.started":"2024-09-23T08:56:05.631859Z"},"trusted":true},"outputs":[],"source":["!pip install segmentation-models-pytorch -q"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-23T08:56:26.381604Z","iopub.status.busy":"2024-09-23T08:56:26.381172Z","iopub.status.idle":"2024-09-23T08:56:34.115209Z","shell.execute_reply":"2024-09-23T08:56:34.114345Z","shell.execute_reply.started":"2024-09-23T08:56:26.381556Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from glob import glob\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","import torchvision\n","from torchvision import models\n","from torchvision import transforms\n","\n","import segmentation_models_pytorch as smp\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{},"source":["### 데이터 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:56:34.116695Z","iopub.status.busy":"2024-09-23T08:56:34.116378Z","iopub.status.idle":"2024-09-23T08:56:34.366239Z","shell.execute_reply":"2024-09-23T08:56:34.365296Z","shell.execute_reply.started":"2024-09-23T08:56:34.116650Z"},"trusted":true},"outputs":[],"source":["image_list = glob('/kaggle/input/car-segmentation/car-segmentation/images/*')\n","\n","mask_list = glob('/kaggle/input/car-segmentation/car-segmentation/masks/*')\n","len(image_list), len(mask_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:56:34.369690Z","iopub.status.busy":"2024-09-23T08:56:34.368936Z","iopub.status.idle":"2024-09-23T08:56:40.487528Z","shell.execute_reply":"2024-09-23T08:56:40.486579Z","shell.execute_reply.started":"2024-09-23T08:56:34.369639Z"},"trusted":true},"outputs":[],"source":["fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n","axes = axes.flatten()\n","\n","for i in range(4):\n","    img_path = image_list[i]\n","    mask_path = image_list[i].replace('images', 'masks')\n","    \n","    axes[2 * i].imshow(Image.open(img_path))\n","    axes[2 * i].set_title(f'Image {i+1}')\n","    axes[2 * i].axis('off')\n","    \n","    axes[2 * i + 1].imshow(Image.open(mask_path))\n","    axes[2 * i + 1].set_title(f'Mask {i+1}')\n","    axes[2 * i + 1].axis('off')"]},{"cell_type":"markdown","metadata":{},"source":["### 클래스 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:56:40.489123Z","iopub.status.busy":"2024-09-23T08:56:40.488765Z","iopub.status.idle":"2024-09-23T08:56:40.515834Z","shell.execute_reply":"2024-09-23T08:56:40.514880Z","shell.execute_reply.started":"2024-09-23T08:56:40.489080Z"},"trusted":true},"outputs":[],"source":["with open('/kaggle/input/car-segmentation/car-segmentation/classes.txt', 'r') as f:\n","    cls_list = f.read().split(',')\n","    cls_list = [cls.strip() for cls in cls_list]\n","print(cls_list)\n","num_classes = len(cls_list)"]},{"cell_type":"markdown","metadata":{},"source":["### 마스크 고유값 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:56:40.517135Z","iopub.status.busy":"2024-09-23T08:56:40.516865Z","iopub.status.idle":"2024-09-23T08:56:40.607959Z","shell.execute_reply":"2024-09-23T08:56:40.607033Z","shell.execute_reply.started":"2024-09-23T08:56:40.517105Z"},"trusted":true},"outputs":[],"source":["unique, counts = np.unique(mask_list, return_counts=True)\n","for mask_path in mask_list:\n","    mask = Image.open(mask_path)\n","    mask = np.array(mask)\n","    print(mask)\n","#     print(mask.shape)\n","    print(np.unique(mask))\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["### 이미지-마스크 겹쳐 그리기\n","`torchvision.utils.draw_segmentation_masks`"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:56:40.609553Z","iopub.status.busy":"2024-09-23T08:56:40.609179Z","iopub.status.idle":"2024-09-23T08:56:40.620534Z","shell.execute_reply":"2024-09-23T08:56:40.619504Z","shell.execute_reply.started":"2024-09-23T08:56:40.609519Z"},"trusted":true},"outputs":[],"source":["def imgs_with_masks(img_dir, start):\n","    img_dir = img_dir[start: start + 4]\n","    fig, axes = plt.subplots(1, 4, figsize=(15, 8))\n","    \n","    for i, img_path in enumerate(img_dir):\n","        # 이미지 및 마스크 불러오기\n","        img = torchvision.io.read_image(img_path)\n","        mask = torchvision.io.read_image(img_path.replace('images', 'masks')).squeeze(0)  # 마스크에서 불필요한 채널 제거\n","\n","        # 마스크를 원-핫 인코딩하여 5개의 클래스로 변환\n","        one_hot_mask = F.one_hot(mask.to(torch.int64), num_classes=num_classes).permute(2, 0, 1).float()\n","        print(img.shape, mask.shape, one_hot_mask.shape)\n","        \n","        # 각 마스크 채널을 True/False로 변환하여 오버레이 생성\n","        overlayed = torchvision.utils.draw_segmentation_masks(img, \n","                                                              one_hot_mask.to(torch.bool), \n","                                                              alpha=0.5, \n","                                                              colors=['black', 'green', 'blue', 'yellow', 'purple'])\n","\n","        axes[i].imshow(overlayed.permute(1, 2, 0))\n","        axes[i].axis('off')\n","        axes[i].set_title(f'Image {i+1}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:56:40.622390Z","iopub.status.busy":"2024-09-23T08:56:40.622038Z","iopub.status.idle":"2024-09-23T08:56:46.799699Z","shell.execute_reply":"2024-09-23T08:56:46.798819Z","shell.execute_reply.started":"2024-09-23T08:56:40.622358Z"},"trusted":true},"outputs":[],"source":["imgs_with_masks(image_list, 0)"]},{"cell_type":"markdown","metadata":{},"source":["### 3차원이 아닌 이미지 제거"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:56:46.801407Z","iopub.status.busy":"2024-09-23T08:56:46.800986Z","iopub.status.idle":"2024-09-23T08:57:04.635213Z","shell.execute_reply":"2024-09-23T08:57:04.634165Z","shell.execute_reply.started":"2024-09-23T08:56:46.801364Z"},"trusted":true},"outputs":[],"source":["exclude = []\n","\n","for img_path in image_list:\n","    img = Image.open(img_path)\n","    img = np.array(img)\n","    if img.ndim != 3:\n","        print(img.shape)\n","        print(img.ndim)\n","        print(img_path)\n","        exclude.append(img_path)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:57:04.639860Z","iopub.status.busy":"2024-09-23T08:57:04.639453Z","iopub.status.idle":"2024-09-23T08:57:04.644646Z","shell.execute_reply":"2024-09-23T08:57:04.643569Z","shell.execute_reply.started":"2024-09-23T08:57:04.639824Z"},"trusted":true},"outputs":[],"source":["for ex in exclude:\n","    image_list.remove(ex)\n","    mask_list.remove(ex.replace('images', 'masks'))"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset\n","- Image: (B, 3, H, W)\n","- Mask: (B, H, W)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:57:04.646259Z","iopub.status.busy":"2024-09-23T08:57:04.645878Z","iopub.status.idle":"2024-09-23T08:57:04.657203Z","shell.execute_reply":"2024-09-23T08:57:04.656304Z","shell.execute_reply.started":"2024-09-23T08:57:04.646207Z"},"trusted":true},"outputs":[],"source":["class CarDataset(Dataset):\n","    def __init__(self, image_list, mask_list, transform_img, transform_mask, num_classes=num_classes):\n","        \n","        self.image_list = image_list\n","        self.mask_list = mask_list\n","        self.transform_img = transform_img\n","        self.transform_mask = transform_mask\n","        self.num_classes = num_classes\n","        \n","    def __len__(self):\n","        \n","        return len(self.image_list)\n","    \n","    def __getitem__(self, idx):\n","        \n","        image_path = self.image_list[idx]\n","        mask_path = image_path.replace('images', 'masks')\n","        \n","        image = Image.open(image_path)\n","        mask = torchvision.io.read_image(mask_path)\n","        \n","        \n","        # 이미지 Channel=4 -> RGBA\n","        if image.mode == 'RGBA':\n","            image = image.convert('RGB')\n","        \n","        image = self.transform_img(image)\n","        mask = self.transform_mask(mask).squeeze(0).to(torch.long)\n","        \n","        return image, mask"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:57:04.658637Z","iopub.status.busy":"2024-09-23T08:57:04.658340Z","iopub.status.idle":"2024-09-23T08:57:04.671097Z","shell.execute_reply":"2024-09-23T08:57:04.670248Z","shell.execute_reply.started":"2024-09-23T08:57:04.658606Z"},"trusted":true},"outputs":[],"source":["transform_img = transforms.Compose([transforms.ToTensor(), \n","                                    transforms.Resize((224, 224)), \n","                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","                                   ])\n","\n","transform_mask = transforms.Compose([transforms.Resize((224, 224)),\n","                                    ])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:57:04.672553Z","iopub.status.busy":"2024-09-23T08:57:04.672227Z","iopub.status.idle":"2024-09-23T08:57:06.767880Z","shell.execute_reply":"2024-09-23T08:57:06.766751Z","shell.execute_reply.started":"2024-09-23T08:57:04.672522Z"},"trusted":true},"outputs":[],"source":["car_dataset = CarDataset(image_list, mask_list, transform_img, transform_mask)\n","print(car_dataset.__len__())\n","\n","train_size = int(0.8 * len(car_dataset))\n","val_size = len(car_dataset) - train_size\n","\n","train_ds, val_ds = random_split(car_dataset, [train_size, val_size])\n","print(f\"Train dataset size: {len(train_ds)} | Validation dataset size: {len(val_ds)}\")\n","\n","train_dl = DataLoader(train_ds, batch_size = 16, shuffle = True)\n","val_dl = DataLoader(val_ds, batch_size = 16, shuffle = False)\n","\n","imgs, masks = next(iter(train_dl))\n","print(imgs.shape, masks.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## 학습 및 추론\n","\n","### SMP 모델\n","\n","- [Model](https://smp.readthedocs.io/en/latest/models.html)\n","\n","- [Encoder](https://smp.readthedocs.io/en/latest/encoders.html)\n","\n","- Pretrained weight\n","\n","주의사항\n","- 모델에 요구되는 input/output shape이 서로 다름\n","- 모델마다 사용할 수 있는 encoder(backbone)의 종류가 다름"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:57:06.770109Z","iopub.status.busy":"2024-09-23T08:57:06.769495Z","iopub.status.idle":"2024-09-23T08:57:07.807487Z","shell.execute_reply":"2024-09-23T08:57:07.806419Z","shell.execute_reply.started":"2024-09-23T08:57:06.770060Z"},"trusted":true},"outputs":[],"source":["unet = # YOUR CODE"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:57:07.809601Z","iopub.status.busy":"2024-09-23T08:57:07.809188Z","iopub.status.idle":"2024-09-23T08:57:08.373847Z","shell.execute_reply":"2024-09-23T08:57:08.372895Z","shell.execute_reply.started":"2024-09-23T08:57:07.809557Z"},"trusted":true},"outputs":[],"source":["dummy_input = torch.randn(1, 3, 224, 224).to(device)\n","dummy_output = unet(dummy_input)\n","dummy_output.shape"]},{"cell_type":"markdown","metadata":{},"source":["### [SMP losses](https://smp.readthedocs.io/en/latest/losses.html)\n","- 모델 prediction mask 유형에 따라 `mode` 인자는 다음 세 가지로 나뉨\n","    - `binary`: 이진 분류\n","        - Pred: (N, 1, H, W)\n","        - Target: (N, H, W)\n","        - Target 값은 0, 1\n","    - `multiclass`: 다중 클래스\n","        - Pred: (N, C, H, W), C = number of classes\n","        - Target: (N, H, W)\n","        - Target 마스크의 unique value는 0, 1, 2, ..., C - 1\n","    - `multilabel`: 다중 레이블\n","        - Pred: (N, C, H, W), C = number of classes\n","        - Target: (N, C, H, W)\n","        - Target 값은 0, 1"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:57:08.375538Z","iopub.status.busy":"2024-09-23T08:57:08.375119Z","iopub.status.idle":"2024-09-23T08:57:08.382006Z","shell.execute_reply":"2024-09-23T08:57:08.381056Z","shell.execute_reply.started":"2024-09-23T08:57:08.375493Z"},"trusted":true},"outputs":[],"source":["mode = 'multiclass'\n","criterion = # YOUR CODE\n","optim = torch.optim.Adam(params = unet.parameters(), lr = 5e-4)\n","epochs = 15"]},{"cell_type":"markdown","metadata":{},"source":["### [SMP Metrics](https://smp.readthedocs.io/en/latest/losses.html)\n","\n","   - SMP metric은 픽셀 별 분류 결과인 Confusion matrix에 의하여 계산됨\n","   - IoU, Dice coef, Accuracy 등 지표를 쓰기 전 prediction과 groud truth 사이의 Confusion matrix(TP, FP, FN, TN)를 구해야 함\n","\n","```python\n","tp, fp, fn, tn = get_stats(pred, target, mode, num_classes, threshold=0.5)\n","```\n","   - pred: tensor(N, C, H, W), C = number of classes\n","   - target: tensor(N, H, W), dtype = long"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:57:08.384130Z","iopub.status.busy":"2024-09-23T08:57:08.383437Z","iopub.status.idle":"2024-09-23T08:57:08.391662Z","shell.execute_reply":"2024-09-23T08:57:08.390826Z","shell.execute_reply.started":"2024-09-23T08:57:08.384080Z"},"trusted":true},"outputs":[],"source":["def metrics(pred, target, mode, num_classes):\n","    # YOUR CODE\n","    \n","    return iou_score, f1_score, accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:57:08.393618Z","iopub.status.busy":"2024-09-23T08:57:08.392857Z","iopub.status.idle":"2024-09-23T08:57:08.498860Z","shell.execute_reply":"2024-09-23T08:57:08.497962Z","shell.execute_reply.started":"2024-09-23T08:57:08.393574Z"},"trusted":true},"outputs":[],"source":["dummy_gt = torch.randint(5, (1, 224, 224)).to(device)\n","# num_classes: mode = 'multiclass'일 경우에만 필요\n","# threshold: mode = 'binary', 'multilabel'일 경우에만 필요\n","iou, dice, acc = metrics(dummy_output, dummy_gt, mode, num_classes)\n","iou, dice, acc"]},{"cell_type":"markdown","metadata":{},"source":["### 학습 루프"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:57:08.500198Z","iopub.status.busy":"2024-09-23T08:57:08.499926Z","iopub.status.idle":"2024-09-23T08:57:08.514388Z","shell.execute_reply":"2024-09-23T08:57:08.513345Z","shell.execute_reply.started":"2024-09-23T08:57:08.500168Z"},"trusted":true},"outputs":[],"source":["def train_and_validate(model, train_loader, val_loader, optim, criterion, epochs, num_classes):\n","    train_losses = []\n","    train_IoUs = []\n","    train_Dices = []\n","    train_PAs = []\n","    \n","    val_losses = []\n","    val_IoUs = []\n","    val_Dices = []\n","    val_PAs = []\n","    \n","    for epoch in range(epochs):\n","        train_loss = 0\n","        train_IoU = 0\n","        train_Dice = 0\n","        train_PA = 0\n","        model.train()\n","        for img, mask in tqdm(train_loader):\n","            img = img.to(device)\n","            mask = mask.to(device)\n","            optim.zero_grad()\n","            output = model(img)\n","            loss = criterion(output, mask)\n","            iou, dice, pa = metrics(output, mask, mode, num_classes)\n","            loss.backward()\n","            optim.step()\n","            train_loss += loss.item()\n","            train_IoU += iou\n","            train_Dice += dice\n","            train_PA += pa\n","            \n","        print(f\"Epoch {epoch + 1}\\nTrain loss: {train_loss / len(train_loader):.2f} | Train IoU: {train_IoU / len(train_loader):.2f} | Train Dice: {train_Dice / len(train_loader):.2f} | Train Pixel Acc: {train_PA / len(train_loader):.2f}\")\n","        train_losses.append(train_loss / len(train_loader))\n","        train_IoUs.append(train_IoU / len(train_loader))\n","        train_Dices.append(train_Dice / len(train_loader))\n","        train_PAs.append(train_PA / len(train_loader))\n","        \n","        val_loss = 0\n","        val_IoU = 0\n","        val_Dice = 0\n","        val_PA = 0\n","        model.eval()\n","        with torch.no_grad():\n","            for img, mask in tqdm(val_loader):\n","                img = img.to(device)\n","                mask = mask.to(device)\n","                output = model(img)\n","                loss = criterion(output, mask)\n","                iou, dice, pa = metrics(output, mask, mode, num_classes)\n","                val_loss += loss.item()\n","                val_IoU += iou\n","                val_Dice += dice\n","                val_PA += pa\n","                \n","            print(f\"Validation loss: {val_loss / len(val_loader):.2f} | Validation IoU: {val_IoU / len(val_loader):.2f} | Validation Dice: {val_Dice / len(val_loader):.2f} | Validation Pixel Acc: {val_PA / len(val_loader):.2f}\\n{'='*100}\")\n","            val_losses.append(val_loss / len(val_loader))\n","            val_IoUs.append(val_IoU / len(val_loader))\n","            val_Dices.append(val_Dice / len(val_loader))\n","            val_PAs.append(val_PA / len(val_loader))\n","            \n","    return train_losses, train_IoUs, train_Dices, train_PAs, val_losses, val_IoUs, val_Dices, val_PAs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T08:59:48.413871Z","iopub.status.busy":"2024-09-23T08:59:48.412981Z","iopub.status.idle":"2024-09-23T09:05:17.812655Z","shell.execute_reply":"2024-09-23T09:05:17.811608Z","shell.execute_reply.started":"2024-09-23T08:59:48.413829Z"},"trusted":true},"outputs":[],"source":["train_losses, train_IoUs, train_Dices, train_PAs, val_losses, val_IoUs, val_Dices, val_PAs = train_and_validate(unet, train_dl, val_dl, optim, criterion, epochs, num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T09:05:23.308302Z","iopub.status.busy":"2024-09-23T09:05:23.307882Z","iopub.status.idle":"2024-09-23T09:05:24.301007Z","shell.execute_reply":"2024-09-23T09:05:24.300142Z","shell.execute_reply.started":"2024-09-23T09:05:23.308264Z"},"trusted":true},"outputs":[],"source":["plt.plot(train_losses, label = 'train loss')\n","plt.plot(val_losses, label = 'val loss')\n","plt.legend()\n","plt.show()\n","plt.plot(train_IoUs, label = 'train mIoU')\n","plt.plot(val_IoUs, label = 'val mIoU')\n","plt.legend()\n","plt.show()\n","plt.plot(train_Dices, label = 'train Dice')\n","plt.plot(val_Dices, label = 'val Dice')\n","plt.legend()\n","plt.show()\n","plt.plot(train_PAs, label = 'train Pixel Accuracy')\n","plt.plot(val_PAs, label = 'val Pixel Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T09:06:15.366557Z","iopub.status.busy":"2024-09-23T09:06:15.365806Z","iopub.status.idle":"2024-09-23T09:06:15.375954Z","shell.execute_reply":"2024-09-23T09:06:15.375038Z","shell.execute_reply.started":"2024-09-23T09:06:15.366519Z"},"trusted":true},"outputs":[],"source":["def plot_batch(model, data_loader):\n","    model.eval()\n","    with torch.no_grad():\n","        for img, mask in tqdm(data_loader):\n","            img = img.to(device)\n","            output = model(img)\n","            \n","            # output에서 가장 높은 클래스 인덱스 선택 (배치에서 각 픽셀별로 argmax)\n","            output = torch.argmax(output, dim=1).cpu().numpy()  # (batch_size, H, W)\n","            \n","            img = img.cpu().numpy().transpose(0, 2, 3, 1)  # (batch_size, H, W, 3)\n","            mask = mask.cpu().numpy()  # (batch_size, H, W)\n","            break\n","    \n","    for i in range(data_loader.batch_size):\n","        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","        \n","        # 원본 이미지 시각화\n","        ax[0].imshow(img[i])\n","        ax[0].set_title('image')\n","        \n","        # 마스크 시각화 (vmin=0, vmax=5로 클래스 범위를 설정)\n","        ax[1].imshow(mask[i], cmap='gray', vmin=0, vmax=5)\n","        ax[1].set_title('mask')\n","        \n","        # 예측 마스크 시각화 (vmin=0, vmax=5로 클래스 범위를 설정)\n","        ax[2].imshow(output[i], cmap='gray', vmin=0, vmax=5)\n","        ax[2].set_title('predicted mask')\n","        \n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T09:06:24.342193Z","iopub.status.busy":"2024-09-23T09:06:24.341811Z","iopub.status.idle":"2024-09-23T09:06:36.157068Z","shell.execute_reply":"2024-09-23T09:06:36.156088Z","shell.execute_reply.started":"2024-09-23T09:06:24.342158Z"},"trusted":true},"outputs":[],"source":["plot_batch(unet, val_dl)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1005067,"sourceId":1705856,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
