{"cells":[{"cell_type":"markdown","metadata":{"id":"nyjyu4FzUAVw"},"source":["# 신경망 학습"]},{"cell_type":"markdown","metadata":{"id":"VQvNez4qydhL"},"source":["## 단순한 신경망 구현 : Logic Gate"]},{"cell_type":"markdown","metadata":{"id":"-7te43hqyiiJ"},"source":["### 필요한 모듈 import"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Qf2F_YbdybBE"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","# plt.style.use('seaborn-whitegrid')"]},{"cell_type":"markdown","metadata":{"id":"orUoPmDcymhj"},"source":["### 하이퍼 파라미터(Hyper Parameter)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"bOAmMxo0ymDF"},"outputs":[],"source":["epochs = 1000\n","lr = 0.1"]},{"cell_type":"markdown","metadata":{"id":"BjmLWgFVysnq"},"source":["### 유틸 함수들(Util Functions)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Y4OMFGrjyq1c"},"outputs":[],"source":["def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def mean_squared_error(y_pred, y_true): # MSE\n","    return np.mean(np.power(y_true - y_pred, 2))\n","\n","def cross_entropy_error(y_pred, y_true):\n","    if y_true.ndim == 1:\n","        y_true = y_true.reshape(1, -1)\n","        y_pred = y_pred.reshape(1, -1)\n","    delta = 1e-7\n","    return -np.sum(y_true * np.log(y_pred + delta))\n","\n","def cross_entropy_error_for_batch(y_pred, y_true):\n","    if y_true.ndim == 1:\n","        y_true = y_true.reshape(1, -1)\n","        y_pred = y_pred.reshape(1, -1)\n","    delta = 1e-7\n","    batch_size = y_pred.shape[0]\n","    return -np.sum(y_true * np.log(y_pred + delta)) / batch_size\n","\n","def cross_entropy_error_for_bin(y_pred, y_true):\n","    return 0.5 * np.sum(-y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred))\n","\n","def softmax(a):\n","    exp_a = np.exp(a)\n","    sum_exp_a = np.sum(exp_a)\n","    y = exp_a / sum_exp_a\n","    return y\n","\n","def differential(f, x):\n","    eps = 1e-5\n","    diff_value = np.zeros_like(x)\n","\n","    for i in range(x.shape[0]):\n","      temp_val = x[i]\n","\n","      x[i] = temp_val + eps\n","      f_h1 = f(x)\n","      x[i] = temp_val - eps\n","      f_h2 = f(x)\n","\n","      diff_value[i] = (f_h1 - f_h2) / (2*eps)\n","      x[i] = temp_val\n","\n","    return diff_value\n"]},{"cell_type":"markdown","metadata":{"id":"h5Z2LTT_y3i5"},"source":["### 신경망"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gMTjjYgdy3D8"},"outputs":[],"source":["class LogicGateNet():\n","\n","    def __init__(self):\n","        def weight_init():\n","            np.random.seed(1)\n","            weights = np.random.randn(2)\n","            bias = np.random.rand(1)\n","\n","            return weights, bias\n","\n","        self.weights, self.bias = weight_init()\n","\n","    def predict(self, x):\n","        W = self.weights.reshape(-1, 1)\n","        b = self.bias\n","\n","        y_pred = sigmoid(np.dot(x, W) + b)\n","        return y_pred\n","\n","    def loss(self, x, y_true):\n","        y_pred = self.predict(x)\n","        return cross_entropy_error_for_bin(y_pred, y_true)\n","\n","\n","    def get_gradient(self, x, t):\n","        def loss_grad(grad):\n","            return self.loss(x, t)\n","\n","        grad_W = differential(loss_grad, self.weights)\n","        grad_b = differential(loss_grad, self.bias)\n","\n","        return grad_W, grad_b"]},{"cell_type":"markdown","metadata":{"id":"wbNDoH_3zbGZ"},"source":["### AND Gate"]},{"cell_type":"markdown","metadata":{"id":"2P-ib8_RzHTh"},"source":["#### 모델 생성 및 학습"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"rRiaACA6zGom"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0, loss: 1.5631544107938489, Weights: [ 1.59589746 -0.61601809], Bias: [-0.0709192]\n","Epoch: 100, loss: 0.6857716198198381, Weights: [1.56879204 0.80386655], Bias: [-2.15965133]\n","Epoch: 200, loss: 0.4933163179445829, Weights: [2.01797503 1.71943466], Bias: [-3.08693073]\n","Epoch: 300, loss: 0.39121669520130875, Weights: [2.43232215 2.30246439], Bias: [-3.79740008]\n","Epoch: 400, loss: 0.32517260605778037, Weights: [2.79827821 2.73621772], Bias: [-4.37788962]\n","Epoch: 500, loss: 0.2782329581540439, Weights: [3.11937435 3.08729741], Bias: [-4.87028742]\n","Epoch: 600, loss: 0.2429757370144252, Weights: [3.40282534 3.38512949], Bias: [-5.29835365]\n","Epoch: 700, loss: 0.21548037473693, Weights: [3.65539764 3.64508755], Bias: [-5.67707715]\n","Epoch: 800, loss: 0.19343364252289047, Weights: [3.8826028  3.87631196], Bias: [-6.01662862]\n","Epoch: 900, loss: 0.17536766101389684, Weights: [4.08877055 4.08477772], Bias: [-6.32427639]\n"]}],"source":["AND = LogicGateNet()\n","\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","Y = np.array([[0], [0], [0], [1]])\n","\n","train_loss_list = list()\n","\n","for i in range(epochs):\n","  grad_W, grad_b = AND.get_gradient(X, Y)\n","\n","  AND.weights -= lr * grad_W\n","  AND.bias -= lr * grad_b\n","\n","  loss = AND.loss(X, Y)\n","  train_loss_list.append(loss)\n","\n","  if i % 100 == 0:\n","    print('Epoch: {}, loss: {}, Weights: {}, Bias: {}'.format(i, loss, AND.weights, AND.bias))"]},{"cell_type":"markdown","metadata":{"id":"PZoyQv_czT7R"},"source":["#### 테스트"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"-7CvWgc9zREa"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.00135483]\n"," [0.08867878]\n"," [0.08889176]\n"," [0.87496677]]\n"]}],"source":["print(AND.predict(X))"]},{"cell_type":"markdown","metadata":{"id":"HoMXNiXWzts-"},"source":["### OR Gate"]},{"cell_type":"markdown","metadata":{"id":"DZ79pc4jzw3O"},"source":["#### 모델 생성 및 학습"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"8gnLmAyQzuoL"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0, loss: 1.0809096617574379, Weights: [ 1.64589746 -0.56601809], Bias: [0.0290808]\n","Epoch: 100, loss: 0.49357719354027074, Weights: [2.46054412 1.41789123], Bias: [-0.15085606]\n","Epoch: 200, loss: 0.3387905043444052, Weights: [2.99128337 2.40254   ], Bias: [-0.68089049]\n","Epoch: 300, loss: 0.2567069051480532, Weights: [3.45447954 3.09023403], Bias: [-1.04026933]\n","Epoch: 400, loss: 0.2058893251466765, Weights: [3.85604032 3.61331053], Bias: [-1.30835956]\n","Epoch: 500, loss: 0.17136486342223992, Weights: [4.20522361 4.03382908], Bias: [-1.52254386]\n","Epoch: 600, loss: 0.14643542957877495, Weights: [4.51155581 4.38495379], Bias: [-1.70108626]\n","Epoch: 700, loss: 0.1276326896734973, Weights: [4.78305736 4.68615553], Bias: [-1.85419212]\n","Epoch: 800, loss: 0.11297468569490247, Weights: [5.02607716 4.9497581 ], Bias: [-1.98817781]\n","Epoch: 900, loss: 0.10124619155853576, Weights: [5.24556341 5.18403507], Bias: [-2.10724704]\n"]}],"source":["OR = LogicGateNet()\n","\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","Y_2 = np.array([[0], [1], [1], [1]])\n","\n","train_loss_list = list()\n","\n","for i in range(epochs):\n","  grad_W, grad_b = OR.get_gradient(X, Y_2)\n","\n","  OR.weights -= lr * grad_W\n","  OR.bias -= lr * grad_b\n","\n","  loss = OR.loss(X, Y_2)\n","  train_loss_list.append(loss)\n","\n","  if i % 100 == 0:\n","    print('Epoch: {}, loss: {}, Weights: {}, Bias: {}'.format(i, loss, OR.weights, OR.bias))"]},{"cell_type":"markdown","metadata":{"id":"jWmEtX_VnLSI"},"source":["#### 테스트"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"JwPpOs3-z2vU"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.09855987]\n"," [0.9600543 ]\n"," [0.96195283]\n"," [0.9998201 ]]\n"]}],"source":["print(OR.predict(X))"]},{"cell_type":"markdown","metadata":{"id":"JEBhczCIz57Q"},"source":["### NAND Gate"]},{"cell_type":"markdown","metadata":{"id":"TzQaaHKKz8sZ"},"source":["#### 모델 생성 및 학습"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"h463QUQRz8PS"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0, loss: 1.603677074279408, Weights: [ 1.59589746 -0.61601809], Bias: [0.0290808]\n","Epoch: 100, loss: 0.7873231739664462, Weights: [-0.50361782 -1.26393998], Bias: [1.7582226]\n","Epoch: 200, loss: 0.5414420689182001, Weights: [-1.52310599 -1.80762764], Bias: [2.80030819]\n","Epoch: 300, loss: 0.42033313569752706, Weights: [-2.15140117 -2.27070443], Bias: [3.57190115]\n","Epoch: 400, loss: 0.3449943036401833, Weights: [-2.61139692 -2.66670316], Bias: [4.19084654]\n","Epoch: 500, loss: 0.2926847258646174, Weights: [-2.98032888 -3.00820355], Bias: [4.7100911]\n","Epoch: 600, loss: 0.25400247457515496, Weights: [-3.2913936  -3.30645195], Bias: [5.15814837]\n","Epoch: 700, loss: 0.2241746807206239, Weights: [-3.56165903 -3.57027914], Bias: [5.55241292]\n","Epoch: 800, loss: 0.20046325191287548, Weights: [-3.80117405 -3.80635564], Bias: [5.90442387]\n","Epoch: 900, loss: 0.1811661106592213, Weights: [-4.01646302 -4.01970994], Bias: [6.22229579]\n"]}],"source":["NAND = LogicGateNet()\n","\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","Y_3 = np.array([[1], [1], [1], [0]])\n","\n","train_loss_list = list()\n","\n","for i in range(epochs):\n","    grad_W, grad_b = NAND.get_gradient(X, Y_3)\n","\n","    NAND.weights -= lr * grad_W\n","    NAND.bias -= lr * grad_b\n","\n","    loss = NAND.loss(X, Y_3)\n","    \n","    train_loss_list.append(loss)\n","\n","    if i % 100 == 0:\n","        print('Epoch: {}, loss: {}, Weights: {}, Bias: {}'.format(i, loss, NAND.weights, NAND.bias))\n"]},{"cell_type":"markdown","metadata":{"id":"jR-rHaTU0Mga"},"source":["#### 테스트"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"WpzKW6sm0Ghp"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.99851256]\n"," [0.90861957]\n"," [0.90879523]\n"," [0.12861037]]\n"]}],"source":["print(NAND.predict(X))"]},{"cell_type":"markdown","metadata":{"id":"NiTWfSQ60Zl2"},"source":["### XOR Gate"]},{"cell_type":"markdown","metadata":{"id":"hmmL0VIu0bXq"},"source":["#### 모델 생성 및 학습"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"0CGm0r1M0a9M"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 100, loss: 1.4026852245456056, Weights: [ 0.47012771 -0.19931523], Bias: [-0.16097708]\n","Epoch: 200, loss: 1.3879445622848308, Weights: [ 0.1572739  -0.03387161], Bias: [-0.07321056]\n","Epoch: 300, loss: 1.386492030048381, Weights: [0.05525161 0.00089673], Bias: [-0.03330094]\n","Epoch: 400, loss: 1.3863236205351948, Weights: [0.02049628 0.00504503], Bias: [-0.01514784]\n","Epoch: 500, loss: 1.3862994743646844, Weights: [0.0080051  0.00361297], Bias: [-0.00689034]\n","Epoch: 600, loss: 1.3862953430687464, Weights: [0.00326661 0.00201812], Bias: [-0.00313421]\n","Epoch: 700, loss: 1.3862945581495083, Weights: [0.00137938 0.00102449], Bias: [-0.00142566]\n","Epoch: 800, loss: 1.38629440139037, Weights: [0.00059716 0.00049628], Bias: [-0.00064849]\n","Epoch: 900, loss: 1.3862943694120307, Weights: [0.00026303 0.00023435], Bias: [-0.00029498]\n","Epoch: 1000, loss: 1.386294362832352, Weights: [0.0001172  0.00010905], Bias: [-0.00013418]\n"]}],"source":["XOR = LogicGateNet()\n","\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","Y_4 = np.array([[0], [1], [1], [0]])\n","\n","train_loss_list = list()\n","\n","for i in range(epochs):\n","  grad_W, grad_b = XOR.get_gradient(X, Y_4)\n","\n","  XOR.weights -= lr * grad_W\n","  XOR.bias -= lr * grad_b\n","\n","  loss = XOR.loss(X, Y_4)\n","  train_loss_list.append(loss)\n","\n","  if i % 100 == 99:\n","    print('Epoch: {}, loss: {}, Weights: {}, Bias: {}'.format(i+1, loss, XOR.weights, XOR.bias))"]},{"cell_type":"markdown","metadata":{"id":"Cy-ktElI0o5P"},"source":["#### 테스트"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"2xHq1r8brp_f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.49996646]\n"," [0.49999372]\n"," [0.49999575]\n"," [0.50002302]]\n"]}],"source":["print(XOR.predict(X))"]},{"cell_type":"markdown","metadata":{"id":"VAlq_-6E1nIq"},"source":["#### 2층 신경망으로 XOR 게이트 구현(1)\n","\n","- 얕은 신경망, Shallow Neural Network\n","\n","- 두 논리게이트(NAND, OR)를 통과하고  \n","  AND 게이트로 합쳐서 구현\n","\n","- 06 신경망 구조 참고"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"mr7nYMG20jTo"},"outputs":[],"source":["X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","Y_5 = np.array([[0], [1], [1], [0]])\n","\n","\n","s1 = NAND.predict(X)\n","s2 = OR.predict(X)\n","X_2 = np.array([s1, s2]).T.reshape(-1, 2)"]},{"cell_type":"markdown","metadata":{"id":"nkTDx8Ah1xHY"},"source":["#### 테스트"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"LK2iD5A91yWQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.12870357]\n"," [0.79966936]\n"," [0.80108545]\n"," [0.14420781]]\n"]}],"source":["print(AND.predict(X_2))"]},{"cell_type":"markdown","metadata":{"id":"i-SK4G262Agn"},"source":["#### 2층 신경망으로 XOR 게이트 구현(2)\n","- 클래스로 구현"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"8RpnHCRZ1zwr"},"outputs":[],"source":["class XORNet():\n","\n","  def __init__(self):\n","      np.random.seed(1)\n","\n","      def weight_init():\n","         params = {}\n","         params['W1'] = np.random.randn(2)\n","         params['b1'] = np.random.rand(2)\n","         params['W2'] = np.random.randn(2)\n","         params['b2'] = np.random.rand(1)\n","         return params\n","\n","      self.params = weight_init()\n","\n","  def predict(self, x):\n","      \n","    #   A1 = np.dot(x, self.params['W1']) + self.params['b1']\n","    #   Z1 = sigmoid(A1)\n","    \n","    #   A2 = np.dot(Z1, self.params['W2']) + self.params['b2']\n","    #   y = sigmoid(A2)\n","\n","      W1, W2 = self.params['W1'].reshape(-1, 1), self.params['W2'].reshape(-1, 1)\n","      b1, b2 = self.params['b1'], self.params['b2']\n","      \n","      A1 = np.dot(x, W1) + b1\n","      Z1 = sigmoid(A1)\n","\n","      A2 = np.dot(Z1, W2) + b2\n","      y = sigmoid(A2)\n","\n","      return y\n","\n","  def loss(self, x, y_true):\n","      y_pred = self.predict(x)\n","      return cross_entropy_error_for_bin(y_pred, y_true)\n","\n","  def get_gradient(self, x, t):\n","      def loss_grad(grad):\n","          return self.loss(x, t)\n","\n","      # 경사하강법\n","      grad = {}\n","      grad['W1'] = differential(loss_grad, self.params['W1'])\n","      grad['b1'] = differential(loss_grad, self.params['b1'])\n","      grad['W2'] = differential(loss_grad, self.params['W2'])\n","      grad['b2'] = differential(loss_grad, self.params['b2'])\n","      \n","\n","      return grad"]},{"cell_type":"markdown","metadata":{"id":"lplK_x0l2YLh"},"source":["#### 하이퍼 파라미터(Hyper Parameter)\n","- 재조정"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"qf-3wWSv2b7l"},"outputs":[],"source":["lr = 0.3"]},{"cell_type":"markdown","metadata":{"id":"lmHKd45d2JbJ"},"source":["#### 모델 생성 및 학습"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"cQNd3XVd2Gj7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 100, loss: 1.3535614442476163\n","Epoch: 200, loss: 1.2827154568318164\n","Epoch: 300, loss: 0.8968907892865843\n","Epoch: 400, loss: 0.3387197141366393\n","Epoch: 500, loss: 0.18121344476695228\n","Epoch: 600, loss: 0.11991186457620501\n","Epoch: 700, loss: 0.08861936864874957\n","Epoch: 800, loss: 0.06992180653155687\n","Epoch: 900, loss: 0.05758041353110403\n","Epoch: 1000, loss: 0.048860935684807164\n"]}],"source":["XOR = XORNet()\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","Y_5 = np.array([[0], [1], [1], [0]])\n","\n","train_loss_list = list()\n","\n","for i in range(epochs):\n","  grad = XOR.get_gradient(X, Y_5)\n","\n","  for key in ('W1', 'b1', 'W2', 'b2'):\n","    XOR.params[key] -= lr * grad[key]\n","\n","  loss = XOR.loss(X, Y_5)\n","  # print(loss)\n","  train_loss_list.append(loss)\n","\n","  if i % 100 == 99:\n","    print('Epoch: {}, loss: {}'.format(i+1, loss))"]},{"cell_type":"markdown","metadata":{"id":"IIV_GsoG2eDs"},"source":["#### 테스트"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Dpr0nZhc2Szr"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.0217367 ]\n"," [0.96884394]\n"," [0.97816819]\n"," [0.0217794 ]]\n"]}],"source":["print(XOR.predict(X))"]},{"cell_type":"markdown","metadata":{"id":"_1IuDL8R7wrx"},"source":["## 다중 클래스 분류 : MNIST Dataset"]},{"cell_type":"markdown","metadata":{"id":"9CiJ5Gmq9Wpa"},"source":["### 배치 처리\n","- 학습 데이터 전체를 한번에 진행하지 않고  \n","  일부 데이터(샘플)을 확률적으로 구해서 조금씩 나누어 진행\n","\n","- 확률적 경사 하강법(Stochastic Gradient Descent) 또는  \n","  미니 배치 학습법(mini-batch learning)이라고도 부름"]},{"cell_type":"markdown","metadata":{"id":"YUDNWwj49byH"},"source":["#### 신경망 구현 : MNIST"]},{"cell_type":"markdown","metadata":{"id":"WjBRQYlP74GM"},"source":["#### 필요한 모듈 임포트"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"h0lJbkuW71lm"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from keras.datasets import mnist\n","import time\n","from tqdm.notebook import tqdm"]},{"cell_type":"markdown","metadata":{"id":"MDvtEiD77_gu"},"source":["#### 데이터 로드"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"4WL7zXMl_uo9"},"outputs":[],"source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()"]},{"cell_type":"markdown","metadata":{"id":"e_rNg5Jn8FRA"},"source":["#### 데이터 확인"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"u4wpsQGA8BOO"},"outputs":[{"name":"stdout","output_type":"stream","text":["(60000, 28, 28) (60000,)\n","(10000, 28, 28) (10000,)\n"]}],"source":["print(x_train.shape, y_train.shape)\n","print(x_test.shape, y_test.shape)\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"pU7nvkHO8IFR"},"outputs":[{"name":"stdout","output_type":"stream","text":["(28, 28)\n","0 255\n"]},{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x167db313250>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["img = x_train[0]\n","print(img.shape)\n","print(img.min(), img.max())\n","plt.imshow(img, cmap='gray')"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"WbBA1Kl18KGT"},"outputs":[{"name":"stdout","output_type":"stream","text":["5\n"]}],"source":["label = y_train[0]\n","print(label)"]},{"cell_type":"markdown","metadata":{"id":"MTFu8i-z8U_C"},"source":["#### 데이터 전처리 (Data Preprocessing)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"q76pjKDVftHJ"},"outputs":[],"source":["def flatten_for_mnist(x):\n","    temp = np.zeros((x.shape[0], x[0].size))\n","\n","    for idx, data in enumerate(x):\n","        temp[idx ,:] = data.flatten()\n","\n","    return temp"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"vvMWrDOR8Mns"},"outputs":[{"name":"stdout","output_type":"stream","text":["(60000, 784)\n","(10000, 784)\n","(60000, 10)\n","(10000, 10)\n"]}],"source":["x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","x_train = flatten_for_mnist(x_train)\n","x_test = flatten_for_mnist(x_test)\n","\n","print(x_train.shape)\n","print(x_test.shape)\n","\n","y_train_ohe = tf.one_hot(y_train, depth=10).numpy()\n","y_test_ohe = tf.one_hot(y_test, depth=10).numpy()\n","\n","print(y_train_ohe.shape)\n","print(y_test_ohe.shape)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"9LjpWz0dotJs"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0 0.0\n","[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"]}],"source":["print(x_train[0].max(), x_train[0].min())\n","print(y_train_ohe[0])"]},{"cell_type":"markdown","metadata":{"id":"5GUaa92Y9RhY"},"source":["#### 하이퍼 파라미터(Hyper Parameter)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"sk3FXXLi9Th5"},"outputs":[],"source":["epochs = 2\n","lr = 0.1\n","batch_size = 100\n","train_size = x_train.shape[0]"]},{"cell_type":"markdown","metadata":{"id":"5lMJ0h8p8iZl"},"source":["#### 사용되는 함수들(Util Functions)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"bSlqZ2Xx8hFn"},"outputs":[],"source":["def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def mean_squared_error(y_pred, y_true):\n","    return np.mean(np.power(y_true - y_pred, 2))\n","\n","def cross_entropy_error(y_pred, y_true):\n","    if y_true.ndim == 1:\n","        y_true = y_true.reshape(1, -1)\n","        y_pred = y_pred.reshape(1, -1)\n","    delta = 1e-7\n","    return -np.sum(y_true * np.log(y_pred + delta))\n","\n","def cross_entropy_error_for_batch(y_pred, y_true):\n","    if y_true.ndim == 1:\n","        y_true = y_true.reshape(1, -1)\n","        y_pred = y_pred.reshape(1, -1)\n","    delta = 1e-7\n","    batch_size = y_pred.shape[0]\n","    return -np.sum(y_true * np.log(y_pred + delta)) / batch_size\n","\n","def cross_entropy_error_for_bin(y_pred, y_true):\n","    return 0.5 * np.sum(-y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred))\n","\n","def softmax(a):\n","    exp_a = np.exp(a)\n","    sum_exp_a = np.sum(exp_a)\n","    y = exp_a / sum_exp_a\n","    return y\n","\n","def differential_1d(f, x):\n","    eps = 1e-5\n","    diff_value = np.zeros_like(x)\n","\n","    for i in range(x.shape[0]):\n","      temp_val = x[i]\n","\n","      x[i] = temp_val + eps\n","      f_h1 = f(x)\n","      x[i] = temp_val - eps\n","      f_h2 = f(x)\n","\n","      diff_value[i] = (f_h1 - f_h2) / (2*eps)\n","      x[i] = temp_val\n","\n","    return diff_value\n","\n","def differential_2d(f, X):\n","    if X.ndim == 1:\n","        return differential_1d(f, X)\n","    else :\n","        grad = np.zeros_like(X)\n","\n","        for idx, x in enumerate(X):\n","            grad[idx] = differential_1d(f, x)\n","\n","        return grad\n"]},{"cell_type":"markdown","metadata":{"id":"sSoV9fyj8_u7"},"source":["#### 2층 신경망으로 구현"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"XBObD5Fw89HI"},"outputs":[],"source":["class MyModel():\n","\n","  def __init__(self):\n","\n","      def weight_init(input_nodes, hidden_nodes, output_nodes):\n","         np.random.seed(777)\n","\n","\n","         params = {}\n","         params['W1'] = 0.01 * np.random.randn(input_nodes, hidden_nodes)\n","         params['b1'] = np.zeros(hidden_nodes)\n","         params['W2'] = 0.01 * np.random.randn(hidden_nodes, output_nodes)\n","         params['b2'] = np.zeros(output_nodes)\n","\n","         return params\n","\n","      self.params = weight_init(784, 64, 10)\n","\n","  def predict(self, x):\n","      W1, W2 = self.params['W1'], self.params['W2']\n","      b1, b2 = self.params['b1'], self.params['b2']\n","\n","      A1 = np.dot(x, W1) + b1\n","      Z1 = sigmoid(A1)\n","      A2 = np.dot(Z1, W2) + b2\n","      y = softmax(A2)\n","      return y\n","\n","  def loss(self, x, y_true):\n","      y_pred = self.predict(x)\n","      return cross_entropy_error_for_bin(y_pred, y_true)\n","\n","  def accuracy(self, x, y_true):\n","      y_pred = self.predict(x)\n","      y_argmax = np.argmax(y_pred, axis=1)\n","      y_true_argmax = np.argmax(y_true, axis=1)\n","\n","      accuracy = np.mean(y_argmax == y_true_argmax)\n","      return accuracy\n","\n","  def get_gradient(self, x, t):\n","      def loss_grad(grad):\n","          return self.loss(x, t)\n","\n","      grad = {}\n","      grad['W1'] = differential_2d(loss_grad, self.params['W1'])\n","      grad['b1'] = differential_2d(loss_grad, self.params['b1'])\n","      grad['W2'] = differential_2d(loss_grad, self.params['W2'])\n","      grad['b2'] = differential_2d(loss_grad, self.params['b2'])\n","\n","      return grad"]},{"cell_type":"markdown","metadata":{"id":"maKNIlK-xJ5k"},"source":["#### 모델 생성 및 학습\n","- 시간 많이 소요"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"XSEARgNIop8t"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd3c9476c91f4ae4b5f489440032e7f5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 1, Train Loss: 465.9060502386832, Train Accuracy: 0.10441666666666667, Test Accuracy: 0.1028\n","Epoch: 2, Train Loss: 361.8440950226591, Train Accuracy: 0.09751666666666667, Test Accuracy: 0.0974\n","총 학습 소요시간: 73.211s\n"]}],"source":["model = MyModel()\n","\n","train_loss_list = list()\n","train_acc_list = list()\n","test_acc_list = list()\n","iter_per_epoch = max(train_size / batch_size, 1)\n","\n","start_time = time.time()\n","\n","for i in tqdm(range(epochs)):\n","\n","    batch_idx = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_idx]\n","    y_batch = y_train_ohe[batch_idx]\n","\n","    grad = model.get_gradient(x_batch, y_batch)\n","\n","    for key in grad.keys():\n","        model.params[key] -= lr * grad[key]\n","\n","    loss = model.loss(x_batch, y_batch)\n","    train_loss_list.append(loss)\n","\n","    train_accuracy = model.accuracy(x_train, y_train_ohe)\n","    test_accuracy = model.accuracy(x_test, y_test_ohe)\n","    train_acc_list.append(train_accuracy)\n","    test_acc_list.append(test_accuracy)\n","\n","    print('Epoch: {}, Train Loss: {}, Train Accuracy: {}, Test Accuracy: {}'.format(i+1, loss, train_accuracy, test_accuracy))\n","\n","end_time = time.time()\n","\n","print('총 학습 소요시간: {:.3f}s'.format(end_time - start_time))"]},{"cell_type":"markdown","metadata":{"id":"b7nL8f20x4zl"},"source":["### 모델의 결과\n","- 모델은 학습이 잘 될 수도, 잘 안될 수도 있음\n","\n","- 만약, 학습이 잘 되지 않았다면,  \n","  학습이 잘 되기 위해서 어떠한 조치를 취해야 하는가?\n","  - 다양한 학습관련 기술이 존재"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
