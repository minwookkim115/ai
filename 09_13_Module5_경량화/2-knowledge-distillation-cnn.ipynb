{"cells":[{"cell_type":"markdown","metadata":{},"source":["# KD(Knowledge Distilation, 지식 증류)"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-12T11:10:29.151161Z","iopub.status.busy":"2024-09-12T11:10:29.150247Z","iopub.status.idle":"2024-09-12T11:10:31.867690Z","shell.execute_reply":"2024-09-12T11:10:31.866607Z","shell.execute_reply.started":"2024-09-12T11:10:29.151117Z"},"trusted":true},"outputs":[],"source":["from tqdm.notebook import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:10:31.870881Z","iopub.status.busy":"2024-09-12T11:10:31.870334Z","iopub.status.idle":"2024-09-12T11:10:33.554311Z","shell.execute_reply":"2024-09-12T11:10:33.553507Z","shell.execute_reply.started":"2024-09-12T11:10:31.870833Z"},"trusted":true},"outputs":[],"source":["# CIFAR-10\n","transforms_cifar = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar)\n","test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{},"source":["## Prep"]},{"cell_type":"markdown","metadata":{},"source":["### Teacher / Student 네트워크 구성"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:10:33.556313Z","iopub.status.busy":"2024-09-12T11:10:33.555565Z","iopub.status.idle":"2024-09-12T11:10:33.569560Z","shell.execute_reply":"2024-09-12T11:10:33.568492Z","shell.execute_reply.started":"2024-09-12T11:10:33.556266Z"},"trusted":true},"outputs":[],"source":["# Teacher model\n","class TeacherNN(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(TeacherNN, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(2048, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x\n","\n","# Student model\n","class StudentNN(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(StudentNN, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(1024, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(256, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["### 학습 함수"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:10:33.572342Z","iopub.status.busy":"2024-09-12T11:10:33.571987Z","iopub.status.idle":"2024-09-12T11:10:33.584865Z","shell.execute_reply":"2024-09-12T11:10:33.584076Z","shell.execute_reply.started":"2024-09-12T11:10:33.572293Z"},"trusted":true},"outputs":[],"source":["def train(model, train_loader, epochs, learning_rate, device):\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    model.train()\n","\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        for x, y_true in tqdm(train_loader):\n","            x, y_true = x.to(device), y_true.to(device)\n","\n","            optimizer.zero_grad()\n","            y_pred = model(x)\n","\n","            loss = criterion(y_pred, y_true)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n","\n","def test(model, test_loader, device):\n","    model.to(device)\n","    model.eval()\n","\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for x, y_true in tqdm(test_loader):\n","            x, y_true = x.to(device), y_true.to(device)\n","\n","            y_pred = model(x)\n","            _, predicted = torch.max(y_pred.data, 1)\n","\n","            total += y_true.size(0)\n","            correct += (predicted == y_true).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    print(f\"Test Accuracy: {accuracy:.2f}%\")\n","    return accuracy"]},{"cell_type":"markdown","metadata":{},"source":["### 모델 선언 및 모델 별 파라미터 수 확인\n","- `teacherModel`: Teacher network\n","- `student_1`: Student network without KD\n","- `student_2`: Student network with KD"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:10:33.586271Z","iopub.status.busy":"2024-09-12T11:10:33.585962Z","iopub.status.idle":"2024-09-12T11:10:33.722656Z","shell.execute_reply":"2024-09-12T11:10:33.721663Z","shell.execute_reply.started":"2024-09-12T11:10:33.586238Z"},"trusted":true},"outputs":[],"source":["torch.manual_seed(42)\n","teacherModel = TeacherNN(num_classes=10).to(device)\n","\n","torch.manual_seed(42)\n","student_1 = StudentNN(num_classes=10).to(device)\n","\n","torch.manual_seed(42)\n","student_2 = StudentNN(num_classes=10).to(device)\n","\n","\n","total_params_teacher = \"{:,}\".format(sum(p.numel() for p in teacherModel.parameters()))\n","print(f\"teacherModel parameters: {total_params_teacher}\")\n","\n","total_params_student_1 = \"{:,}\".format(sum(p.numel() for p in student_1.parameters()))\n","print(f\"student_1 parameters: {total_params_student_1}\")\n","\n","total_params_student_2 = \"{:,}\".format(sum(p.numel() for p in student_2.parameters()))\n","print(f\"student_2 parameters: {total_params_student_2}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 실험"]},{"cell_type":"markdown","metadata":{},"source":["### 실험 0: KD 없이 각 모델 성능 비교"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:10:33.724175Z","iopub.status.busy":"2024-09-12T11:10:33.723866Z","iopub.status.idle":"2024-09-12T11:14:32.424433Z","shell.execute_reply":"2024-09-12T11:14:32.423264Z","shell.execute_reply.started":"2024-09-12T11:10:33.724142Z"},"trusted":true},"outputs":[],"source":["train(teacherModel, train_loader, epochs=20, learning_rate=0.001, device=device)\n","test_accuracy_teacher = test(teacherModel, test_loader, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:14:32.426845Z","iopub.status.busy":"2024-09-12T11:14:32.426398Z","iopub.status.idle":"2024-09-12T11:18:26.852581Z","shell.execute_reply":"2024-09-12T11:18:26.851551Z","shell.execute_reply.started":"2024-09-12T11:14:32.426797Z"},"trusted":true},"outputs":[],"source":["train(student_1, train_loader, epochs=20, learning_rate=0.001, device=device)\n","test_accuracy_student_1 = test(student_1, test_loader, device)"]},{"cell_type":"markdown","metadata":{},"source":["### 실험 1: KD 적용\n","\n","![](https://pytorch.org/tutorials/_static/img/knowledge_distillation/distillation_output_loss.png)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_knowledge_distillation(teacher, student, train_loader, epochs, learning_rate, T, soft_target_loss_weight, ce_loss_weight, device):\n","    ce_loss = nn.CrossEntropyLoss()  # 교차 엔트로피 손실 함수 정의\n","    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n","\n","    teacher.eval()  # teacher model을 평가 모드로 설정 (학습대상 아님)\n","    student.train()  # student model을 학습 모드로 설정\n","\n","    for epoch in range(epochs):\n","        running_loss = 0.0  # 각 epoch의 손실값을 추적\n","\n","        for x, y_true in tqdm(train_loader):\n","            x, y_true = x.to(device), y_true.to(device)\n","\n","            \"\"\"\n","            1. 옵티마이저의 기울기 초기화\n","\n","            2. teacher model의 예측값 계산\n","               - torch.no_grad() 컨텍스트 안에서 teacher model을 사용해 입력 데이터 x에 대한 예측값(로짓) 계산\n","               - 이 과정에서 기울기 계산되지 않도록 설정\n","\n","            3. student model의 예측값 계산\n","               - student model을 사용해 입력 데이터 x에 대한 예측값(로짓) 계산\n","\n","            4. teacher model의 로짓을 사용해 soft label 계산\n","               - T로 나눈 후 softmax를 적용해 soft label 구하기\n","               - soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n","\n","            5. student model의 로짓을 부드럽게 만들어 soft label과 비교할 수 있도록 설정\n","               - T로 나눈 후 log_softmax 적용\n","               - soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n","\n","            6. soft label 손실 계산\n","               - soft_targets와 soft_prob를 이용해 soft label 손실 계산\n","               - 계산된 손실에 대해 T^2을 곱하여 스케일링\n","         soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (T**2)\n","\n","            7. 실제 레이블을 사용한 교차 엔트로피 손실 계산\n","               - y_true와 student_logits을 이용해 교차 엔트로피 손실 계산\n","\n","            8. 두 손실을 가중치에 따라 결합\n","               - soft_target_loss_weight와 ce_loss_weight을 이용해 두 손실 결합\n","\n","            9. 손실 값 역전파\n","               - loss.backward() 호출로 손실에 대한 기울기 계산\n","\n","            10. 옵티마이저를 사용해 가중치 업데이트\n","               - optimizer.step() 호출로 student model의 파라미터 업데이트\n","            \"\"\"\n","\n","            running_loss += loss.item()  # 배치별 손실을 누적\n","\n","        # 각 epoch이 끝날 때 손실 출력\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:18:26.866648Z","iopub.status.busy":"2024-09-12T11:18:26.866381Z","iopub.status.idle":"2024-09-12T11:20:27.776378Z","shell.execute_reply":"2024-09-12T11:20:27.775260Z","shell.execute_reply.started":"2024-09-12T11:18:26.866618Z"},"trusted":true},"outputs":[],"source":["train_knowledge_distillation(teacher=teacherModel, student=student_2, train_loader=train_loader, epochs=10, learning_rate=0.001, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n","test_accuracy_student_2 = test(student_2, test_loader, device)\n","\n","print(f\"Teacher accuracy: {test_accuracy_teacher:.2f}%\")\n","print(f\"Student accuracy without teacher: {test_accuracy_student_1:.2f}%\")\n","print(f\"Student accuracy with CE + KD: {test_accuracy_student_2:.2f}%\")"]},{"cell_type":"markdown","metadata":{},"source":["### 실험 2: KD 적용, Cosine loss\n","\n","![](https://pytorch.org/tutorials/_static/img/knowledge_distillation/cosine_loss_distillation.png)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:20:27.780566Z","iopub.status.busy":"2024-09-12T11:20:27.780170Z","iopub.status.idle":"2024-09-12T11:20:27.794800Z","shell.execute_reply":"2024-09-12T11:20:27.793800Z","shell.execute_reply.started":"2024-09-12T11:20:27.780523Z"},"trusted":true},"outputs":[],"source":["class TeacherCosine(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(TeacherCosine, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(2048, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        flattened_conv_output = torch.flatten(x, 1)\n","        x = self.classifier(flattened_conv_output)\n","        flattened_conv_output_after_pooling = torch.nn.functional.avg_pool1d(flattened_conv_output, 2)\n","        return x, flattened_conv_output_after_pooling\n","\n","\n","class StudentNNCosine(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(StudentNNCosine, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(1024, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(256, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        flattened_conv_output = torch.flatten(x, 1)\n","        x = self.classifier(flattened_conv_output)\n","        return x, flattened_conv_output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:20:27.796407Z","iopub.status.busy":"2024-09-12T11:20:27.796088Z","iopub.status.idle":"2024-09-12T11:20:27.862566Z","shell.execute_reply":"2024-09-12T11:20:27.861587Z","shell.execute_reply.started":"2024-09-12T11:20:27.796367Z"},"trusted":true},"outputs":[],"source":["teacherCosine = TeacherCosine(num_classes=10).to(device)\n","teacherCosine.load_state_dict(teacherModel.state_dict())\n","\n","print(\"Norm of 1st layer for teacherModel:\", torch.norm(teacherModel.features[0].weight).item())\n","print(\"Norm of 1st layer for teacherCosine:\", torch.norm(teacherCosine.features[0].weight).item())\n","\n","torch.manual_seed(42)\n","studentCosine = StudentNNCosine(num_classes=10).to(device)\n","print(\"Norm of 1st layer for studentCosine:\", torch.norm(studentCosine.features[0].weight).item())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:20:27.864032Z","iopub.status.busy":"2024-09-12T11:20:27.863725Z","iopub.status.idle":"2024-09-12T11:20:27.886791Z","shell.execute_reply":"2024-09-12T11:20:27.885839Z","shell.execute_reply.started":"2024-09-12T11:20:27.863999Z"},"trusted":true},"outputs":[],"source":["# Dummy tensor을 입력하여 작동 확인\n","sample_input = torch.randn(128, 3, 32, 32).to(device)\n","\n","logits, hidden_representation = studentCosine(sample_input)\n","\n","# 텐서 shape 출력\n","print(\"Student logits shape:\", logits.shape) # batch_size x total_classes\n","print(\"Student hidden representation shape:\", hidden_representation.shape) # batch_size x hidden_representation_size\n","\n","# Teacher 모델 텐서 입력\n","logits, hidden_representation = teacherCosine(sample_input)\n","\n","# Shape 확인\n","print(\"Teacher logits shape:\", logits.shape) # batch_size x total_classes\n","print(\"Teacher hidden representation shape:\", hidden_representation.shape) # batch_size x hidden_representation_size"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_cosine_loss(teacher, student, train_loader, epochs, learning_rate, hidden_rep_loss_weight, ce_loss_weight, device):\n","    ce_loss = nn.CrossEntropyLoss()  # 교차 엔트로피 손실 함수 정의\n","    cosine_loss = nn.CosineEmbeddingLoss()  # 코사인 임베딩 손실 함수 정의\n","    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n","\n","    teacher.to(device)\n","    student.to(device)\n","    teacher.eval()  # teacher model을 평가 모드로 설정\n","    student.train()  # student model을 학습 모드로 설정\n","\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","\n","        for x, y_true in tqdm(train_loader):\n","            x, y_true = x.to(device), y_true.to(device)\n","\n","            \"\"\"\n","            1. 옵티마이저의 기울기 초기화\n","\n","            2. teacher model의 예측값 계산\n","               - torch.no_grad() 컨텍스트 안에서 teacher model을 사용해 입력 데이터 x에 대한 예측값을 계산하고, \n","                 그 중에서 hidden representation만 추출\n","               - _, teacher_hidden_representation = teacher(x)\n","\n","            3. student model의 예측값 계산\n","               - student model을 사용해 입력 데이터 x에 대한 로짓과 hidden representation을 함께 계산\n","               - student_logits, student_hidden_representation = student(x)\n","\n","            4. 코사인 손실 계산\n","               - student model과 teacher model의 숨겨진 표현을 비교해 코사인 손실 계산\n","               - 타겟 벡터는 모두 1로 설정 (코사인 유사도가 최대가 되도록 학습)\n","               - hidden_rep_loss = cosine_loss(student_hidden_representation, teacher_hidden_representation, target=torch.ones(x.size(0)).to(device))\n","\n","            5. 실제 레이블을 사용한 교차 엔트로피 손실 계산\n","               - y_true와 student_logits을 이용해 교차 엔트로피 손실 계산\n","\n","            6. 두 손실을 가중치에 따라 결합\n","               - hidden_rep_loss_weight와 ce_loss_weight를 이용해 두 손실 결합\n","\n","            7. 손실 값 역전파\n","               - loss.backward() 호출로 손실에 대한 기울기 계산\n","\n","            8. 옵티마이저를 사용해 가중치 업데이트\n","               - optimizer.step() 호출로 student model의 파라미터 업데이트\n","            \"\"\"\n","\n","            running_loss += loss.item()  # 배치별 손실을 누적\n","\n","        # 각 epoch이 끝날 때 손실 출력\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:20:27.899830Z","iopub.status.busy":"2024-09-12T11:20:27.899471Z","iopub.status.idle":"2024-09-12T11:20:27.911907Z","shell.execute_reply":"2024-09-12T11:20:27.910970Z","shell.execute_reply.started":"2024-09-12T11:20:27.899789Z"},"trusted":true},"outputs":[],"source":["def test_multiple_outputs(model, test_loader, device):\n","    model.to(device)\n","    model.eval()\n","\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for x, y_true in tqdm(test_loader):\n","            x, y_true = x.to(device), y_true.to(device)\n","\n","            y_pred, _ = model(x) # Inference 시에는 사용하지 않음\n","            _, predicted = torch.max(y_pred.data, 1)\n","\n","            total += y_true.size(0)\n","            correct += (predicted == y_true).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    print(f\"Test Accuracy: {accuracy:.2f}%\")\n","    return accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:20:27.913672Z","iopub.status.busy":"2024-09-12T11:20:27.913264Z","iopub.status.idle":"2024-09-12T11:22:29.399394Z","shell.execute_reply":"2024-09-12T11:22:29.398283Z","shell.execute_reply.started":"2024-09-12T11:20:27.913617Z"},"trusted":true},"outputs":[],"source":["train_cosine_loss(teacher=teacherCosine, student=studentCosine, train_loader=train_loader, epochs=10, learning_rate=0.001, hidden_rep_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n","\n","test_accuracy_student_ce_and_cosine_loss = test_multiple_outputs(studentCosine, test_loader, device)"]},{"cell_type":"markdown","metadata":{},"source":["### 실험 2: KD 적용, Regression loss\n","\n","![](https://pytorch.org/tutorials/_static/img/knowledge_distillation/fitnets_knowledge_distill.png)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:22:29.402129Z","iopub.status.busy":"2024-09-12T11:22:29.401410Z","iopub.status.idle":"2024-09-12T11:22:29.417141Z","shell.execute_reply":"2024-09-12T11:22:29.416233Z","shell.execute_reply.started":"2024-09-12T11:22:29.402078Z"},"trusted":true},"outputs":[],"source":["class TeacherMSE(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(TeacherMSE, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(2048, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        conv_feature_map = x\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x, conv_feature_map\n","\n","    \n","class StudentMSE(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(StudentMSE, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","        # Include an extra regressor (in our case linear)\n","        self.regressor = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=3, padding=1)\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(1024, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(256, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        regressor_output = self.regressor(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x, regressor_output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_mse_loss(teacher, student, train_loader, epochs, learning_rate, feature_map_weight, ce_loss_weight, device):\n","    ce_loss = nn.CrossEntropyLoss()  # 교차 엔트로피 손실 함수 정의\n","    mse_loss = nn.MSELoss()  # MSE 손실 함수 정의\n","    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n","\n","    teacher.to(device)\n","    student.to(device)\n","    teacher.eval()\n","    student.train()\n","\n","    for epoch in range(epochs):\n","        running_loss = 0.0  # 각 epoch의 손실값을 추적\n","\n","        for x, y_true in tqdm(train_loader):\n","            x, y_true = x.to(device), y_true.to(device)\n","\n","            \"\"\"\n","            1. 옵티마이저의 기울기 초기화\n","\n","            2. teacher model의 예측값 계산\n","               - torch.no_grad() 컨텍스트 안에서 teacher model을 사용해 입력 데이터 x에 대한 예측값을 계산하고,\n","                 그 중에서 feature map만 추출\n","               - _, teacher_feature_map = teacher(x)\n","\n","            3. student model의 예측값 계산\n","               - student model을 사용해 입력 데이터 x에 대한 로짓과 feature map을 함께 계산\n","               - student_logits, regressor_feature_map = student(x)\n","\n","            4. MSE 손실 계산\n","               - student model과 teacher model의 특징 맵을 비교해 MSE 손실 계산\n","               - hidden_rep_loss = mse_loss(regressor_feature_map, teacher_feature_map)\n","\n","            5. 실제 레이블을 사용한 교차 엔트로피 손실 계산\n","               - y_true와 student_logits을 이용해 교차 엔트로피 손실 계산\n","\n","            6. 두 손실을 가중치에 따라 결합\n","               - feature_map_weight와 ce_loss_weight를 이용해 두 손실 결합\n","\n","            7. 손실 값 역전파\n","               - loss.backward() 호출로 손실에 대한 기울기 계산\n","\n","            8. 옵티마이저를 사용해 가중치 업데이트\n","               - optimizer.step() 호출로 student model의 파라미터 업데이트\n","            \"\"\"\n","\n","            running_loss += loss.item()  # 배치별 손실을 누적\n","\n","        # 각 epoch이 끝날 때 손실 출력\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:22:29.434762Z","iopub.status.busy":"2024-09-12T11:22:29.434455Z","iopub.status.idle":"2024-09-12T11:22:29.468743Z","shell.execute_reply":"2024-09-12T11:22:29.467898Z","shell.execute_reply.started":"2024-09-12T11:22:29.434729Z"},"trusted":true},"outputs":[],"source":["torch.manual_seed(42)\n","studentMse = StudentMSE(num_classes=10).to(device)\n","\n","# 가중치 복사\n","teacherMse = TeacherMSE(num_classes=10).to(device)\n","teacherMse.load_state_dict(teacherModel.state_dict())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:22:29.470405Z","iopub.status.busy":"2024-09-12T11:22:29.470016Z","iopub.status.idle":"2024-09-12T11:24:29.901519Z","shell.execute_reply":"2024-09-12T11:24:29.900422Z","shell.execute_reply.started":"2024-09-12T11:22:29.470362Z"},"trusted":true},"outputs":[],"source":["train_mse_loss(teacher=teacherMse, student=studentMse, train_loader=train_loader, epochs=10, learning_rate=0.001, feature_map_weight=0.25, ce_loss_weight=0.75, device=device)\n","test_accuracy_student_ce_and_mse_loss = test_multiple_outputs(studentMse, test_loader, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T11:24:29.903740Z","iopub.status.busy":"2024-09-12T11:24:29.903300Z","iopub.status.idle":"2024-09-12T11:24:29.911072Z","shell.execute_reply":"2024-09-12T11:24:29.910044Z","shell.execute_reply.started":"2024-09-12T11:24:29.903690Z"},"trusted":true},"outputs":[],"source":["print(f\"Teacher accuracy: {test_accuracy_teacher:.2f}%\")\n","print(f\"Student accuracy without teacher: {test_accuracy_student_1:.2f}%\")\n","print(f\"Student accuracy with CE + KD: {test_accuracy_student_2:.2f}%\")\n","print(f\"Student accuracy with CE + CosineLoss: {test_accuracy_student_ce_and_cosine_loss:.2f}%\")\n","print(f\"Student accuracy with CE + RegressorMSE: {test_accuracy_student_ce_and_mse_loss:.2f}%\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
