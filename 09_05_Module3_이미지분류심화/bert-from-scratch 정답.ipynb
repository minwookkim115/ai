{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9325351,"sourceType":"datasetVersion","datasetId":5649457}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport math\nimport numpy as np\nimport pandas as pd\nfrom random import *\nfrom tqdm import tqdm\nfrom itertools import chain\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport nltk\n\n# Modeling\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   # GPU가 없을 경우 CPU를 사용합니다.\nprint(f\"Using {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:25:40.110141Z","iopub.execute_input":"2024-09-05T12:25:40.110826Z","iopub.status.idle":"2024-09-05T12:25:40.122370Z","shell.execute_reply.started":"2024-09-05T12:25:40.110784Z","shell.execute_reply":"2024-09-05T12:25:40.121318Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Using cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"PATH = \"/kaggle/input/clothing-review/Womens Clothing E-Commerce Reviews.csv\"\nraw_df = pd.read_csv(PATH, index_col=0)\ndf = raw_df[['Review Text','Rating']]\ndf.dropna(inplace=True)\ndf = df.drop_duplicates()\ndf.info()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:25:40.685193Z","iopub.execute_input":"2024-09-05T12:25:40.685571Z","iopub.status.idle":"2024-09-05T12:25:40.952515Z","shell.execute_reply.started":"2024-09-05T12:25:40.685536Z","shell.execute_reply":"2024-09-05T12:25:40.951522Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 22634 entries, 0 to 23485\nData columns (total 2 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   Review Text  22634 non-null  object\n 1   Rating       22634 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 530.5+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\n\nnltk.download('stopwords') # NLTK에서 불용어 데이터를 다운로드\nstop_words = set(nltk.corpus.stopwords.words('english')) # 영어 불용어 목록을 가져와서 집합으로 저장\n\n# 텍스트 데이터 전처리 함수\ndef text_preprocessing(text):\n    text = text.lower() # 모든 문자를 소문자로 변환\n    text = re.sub('<.*?>', '', text) # HTML 태그 제거 (정규식을 사용하여 <와 > 사이의 모든 문자 제거)\n    text = re.sub('[^a-zA-Z]', ' ', text) # 알파벳을 제외한 모든 기호 공백으로 대체\n    text = [word for word in text.split() if word not in stop_words] # 불용어 제거 (stop_words 리스트에 없는 단어만 유지)\n    text = ' '.join(text) # 단어 리스트를 공백으로 구분된 문자열로 다시 결합\n    return text # 전처리된 텍스트 반환\n\ndf['cleaned_review'] = df['Review Text'].apply(text_preprocessing)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:25:41.116382Z","iopub.execute_input":"2024-09-05T12:25:41.116695Z","iopub.status.idle":"2024-09-05T12:25:42.109354Z","shell.execute_reply.started":"2024-09-05T12:25:41.116662Z","shell.execute_reply":"2024-09-05T12:25:42.108404Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                         Review Text  Rating  \\\n0  Absolutely wonderful - silky and sexy and comf...       4   \n1  Love this dress!  it's sooo pretty.  i happene...       5   \n2  I had such high hopes for this dress and reall...       3   \n3  I love, love, love this jumpsuit. it's fun, fl...       5   \n4  This shirt is very flattering to all due to th...       5   \n\n                                      cleaned_review  \n0        absolutely wonderful silky sexy comfortable  \n1  love dress sooo pretty happened find store gla...  \n2  high hopes dress really wanted work initially ...  \n3  love love love jumpsuit fun flirty fabulous ev...  \n4  shirt flattering due adjustable front tie perf...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Text</th>\n      <th>Rating</th>\n      <th>cleaned_review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Absolutely wonderful - silky and sexy and comf...</td>\n      <td>4</td>\n      <td>absolutely wonderful silky sexy comfortable</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n      <td>5</td>\n      <td>love dress sooo pretty happened find store gla...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I had such high hopes for this dress and reall...</td>\n      <td>3</td>\n      <td>high hopes dress really wanted work initially ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n      <td>5</td>\n      <td>love love love jumpsuit fun flirty fabulous ev...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This shirt is very flattering to all due to th...</td>\n      <td>5</td>\n      <td>shirt flattering due adjustable front tie perf...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['Rating'] = (df['Rating'] > 3.5).astype(int)\n\nreviews = df['cleaned_review'].tolist()\nratings = df['Rating'].tolist()\n\ndef create_vocab_and_tokenize(reviews, min_freq=0, max_length=64):\n    # 리뷰를 토큰화합니다.\n    def tokenize_text(text):\n        return text.split()\n\n    tokenized_reviews = [tokenize_text(review) for review in reviews]\n\n    # 각 토큰의 발생 횟수를 세어봅니다.\n    token_counts = Counter(chain(*tokenized_reviews))\n\n    # min_freq 이상 출현한 토큰만으로 어휘를 만듭니다.\n    vocab = {token: i for i, (token, count) in enumerate(token_counts.items()) if count >= min_freq}\n\n    # 어휘에 특수 토큰을 추가합니다.\n    vocab = {**{'[PAD]': 0, '[UNK]': 1, '[CLS]': 2, '[SEP]': 3}, **vocab}\n\n    # 리뷰를 입력 ID와 attention masks로 변환합니다.\n    input_ids = []\n    attention_masks = []\n\n    for review in reviews:\n        # 리뷰를 토큰화하고 최대 길이에 맞게 잘라냅니다.\n        tokens = tokenize_text(review)[:max_length-2]\n        # 토큰을 ID로 변환하고, 앞뒤로 [CLS]와 [SEP] 토큰을 추가합니다.\n        input_id = [2] + [vocab.get(token, 1) for token in tokens] + [3]\n        # attention mask를 생성합니다.\n        attention_mask = [1] * len(input_id) + [0] * (max_length - len(input_id))\n        # 입력 ID를 max_length에 맞게 [PAD] 토큰으로 채웁니다.\n        input_id += [0] * (max_length - len(input_id))\n        input_ids.append(input_id)\n        attention_masks.append(attention_mask)\n\n    return vocab, torch.tensor(input_ids), torch.tensor(attention_masks)\n\n# `create_vocab_and_tokenize` 함수를 이용하여 주어진 리뷰 데이터를 토큰화하고 어휘를 생성합니다.\nvocab, input_ids, attention_masks = create_vocab_and_tokenize(reviews)\n\n# 평점(ratings) 데이터를 PyTorch 텐서로 변환합니다.\nratings = torch.tensor(ratings)\n\n# 아래의 세 줄은 GPU 또는 다른 하드웨어 가속기에 텐서를 옮기기 위한 코드입니다.\n# 이를 통해 모델의 학습 및 추론 속도가 향상될 수 있습니다.\n\ninput_ids = input_ids.to(device)\nattention_masks = attention_masks.to(device)\nratings = ratings.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:25:42.111194Z","iopub.execute_input":"2024-09-05T12:25:42.111912Z","iopub.status.idle":"2024-09-05T12:25:43.798859Z","shell.execute_reply.started":"2024-09-05T12:25:42.111864Z","shell.execute_reply":"2024-09-05T12:25:43.797823Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# TensorDataset을 이용하여 input_ids, attention_masks, 그리고 ratings을 포함하는 데이터셋을 생성합니다.\ndataset = TensorDataset(input_ids, attention_masks, ratings)\n\n# 전체 데이터셋의 90%는 훈련 데이터로, 나머지 10%는 검증 데이터로 사용하기 위한 크기를 계산합니다.\ntrain_size = int(0.9 * len(dataset))\nval_size = len(dataset) - train_size\n\n# random_split을 이용하여 데이터셋을 훈련과 검증 데이터셋으로 무작위 분할합니다.\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# 배치의 크기를 설정합니다.\nbatch_size = 64\n\n# 훈련 데이터를 위한 DataLoader를 생성합니다. 이때 무작위 샘플링을 사용하여 각 에폭마다 데이터를 무작위로 섞습니다.\ntrain_dataloader = DataLoader(\n            train_dataset,\n            sampler = RandomSampler(train_dataset),  # 무작위 샘플링\n            batch_size = batch_size\n        )\n\n# 검증 데이터를 위한 DataLoader를 생성합니다. 여기서는 순차적 샘플링을 사용하여 데이터 순서를 그대로 유지합니다.\nvalidation_dataloader = DataLoader(\n            val_dataset,\n            sampler = SequentialSampler(val_dataset),  # 순차적 샘플링\n            batch_size = batch_size\n        )","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:25:43.800570Z","iopub.execute_input":"2024-09-05T12:25:43.801283Z","iopub.status.idle":"2024-09-05T12:25:43.820995Z","shell.execute_reply.started":"2024-09-05T12:25:43.801238Z","shell.execute_reply":"2024-09-05T12:25:43.820198Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# 모델 구현\n![](https://www.researchgate.net/publication/349546860/figure/fig2/AS:994573320994818@1614136166736/The-Transformer-based-BERT-base-architecture-with-twelve-encoder-blocks.ppm)\n","metadata":{}},{"cell_type":"code","source":"# BERT 모델에 사용될 파라미터 설정\n\nmaxlen = 512    # 최대 입력 시퀀스 길이 설정. BERT의 표준 입력 길이는 512입니다.\nvocab_size = 20000 # len(vocab) # 어휘 크기를 계산합니다. 이는 나중에 임베딩 레이어 생성 시 사용됩니다.\nmax_pred = 20   # 예측될 최대 토큰 수 설정. 주로 masked language model 학습에서 사용됩니다.\n\nn_layers = 12   # 트랜스포머 모델의 레이어 수\nn_heads = 8 # 멀티 헤드 어텐션에서의 헤드 수\nd_model = 768   # 임베딩 및 트랜스포머 내부의 은닉 상태 크기\nd_ff = 768 * 4  # Feed Forward 네트워크의 차원. 보통 d_model의 4배로 설정됩니다.\nd_k = d_v = 64  # 멀티 헤드 어텐션에서 K(=Q)와 V의 차원\n\nn_segments = 2  # 입력 시퀀스의 세그먼트 수 (보통 2: A와 B의 두 가지 세그먼트)\ndropout = 0.1   # 모델 내 드롭아웃 비율 설정\nlr = 1e-4   # 학습률 설정\n\nepochs = 5  # 학습할 에폭 수","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-05T12:25:44.419608Z","iopub.execute_input":"2024-09-05T12:25:44.420291Z","iopub.status.idle":"2024-09-05T12:25:44.426252Z","shell.execute_reply.started":"2024-09-05T12:25:44.420253Z","shell.execute_reply":"2024-09-05T12:25:44.425320Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### 활성화 함수\n\nGELU(Gaussian Error Linear Unit)라는 활성화 함수를 구현해봅니다. \n\nGELU는 BERT와 같은 트랜스포머 모델에서 자주 사용되며, 다른 활성화 함수보다 깊은 신경망에서 잘 동작하는 것으로 알려져 있습니다.","metadata":{}},{"cell_type":"code","source":"def gelu(x):\n    # Hugging Face에서 구현한 gelu 활성화 함수\n    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:25:47.114018Z","iopub.execute_input":"2024-09-05T12:25:47.114854Z","iopub.status.idle":"2024-09-05T12:25:47.119208Z","shell.execute_reply.started":"2024-09-05T12:25:47.114816Z","shell.execute_reply":"2024-09-05T12:25:47.118181Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Embedding layer 클래스 선언\n![](https://www.researchgate.net/profile/Akbar-Karimi-4/publication/338934952/figure/fig2/AS:853247933808640@1580441568270/BERT-word-embedding-layer-Devlin-et-al-2018.ppm)\n\n아래는 BERT 모델의 임베딩 레이어를 구현한 것입니다. 임베딩 레이어는 두 가지 주요한 부분으로 구성됩니다:\n\n- 토큰 임베딩(`tok_embedding`): 주어진 입력 토큰(단어나 문자)을 고정된 크기의 벡터로 변환합니다. 이 벡터는 모델이 학습하는 과정에서 업데이트됩니다.\n\n- 위치 임베딩(`pos_embedding`): 트랜스포머 아키텍처는 순차적인 정보를 자동으로 처리하지 않기 때문에, 각 토큰의 위치 정보를 제공하기 위해 위치 임베딩을 사용합니다.\n\n이 두 임베딩은 합쳐져서 각 토큰에 대한 최종 임베딩 벡터를 생성합니다. 그 후, LayerNorm과 Dropout을 통해 임베딩 벡터가 정규화되고, 과적합을 방지하기 위해 일부 노드가 무작위로 0으로 설정됩니다.","metadata":{}},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, vocab_size):\n        super().__init__()\n\n        # 토큰 임베딩: 주어진 단어나 토큰을 d_model 차원의 벡터로 변환\n        self.tok_embedding = nn.Embedding(vocab_size, d_model)\n        # 위치 임베딩: 각 토큰의 위치를 d_model 차원의 벡터로 변환\n        self.pos_embedding = nn.Embedding(maxlen, d_model)\n\n        # 임베딩 후의 벡터를 정규화\n        self.norm = nn.LayerNorm(d_model)\n        # 드롭아웃을 적용하여 모델의 과적합을 방지\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # 입력 x의 시퀀스 길이를 가져옴\n        seq_len = x.size(1) # batch_size * seq_len\n        # 입력 x의 각 토큰에 대한 위치 정보를 생성\n        pos = torch.arange(seq_len, dtype=torch.long, device=x.device) # 0, 1, ..., seq_len-1\n        pos = pos.unsqueeze(0).repeat(x.size(0), 1) # batch_size * seq_len\n\n        # 토큰 임베딩과 위치 임베딩을 합침\n        embedding = self.tok_embedding(x) + self.pos_embedding(pos) # batch_size * seq_len * d_model\n\n        # 임베딩 벡터를 정규화하고 드롭아웃을 적용\n        return self.dropout(self.norm(embedding))","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:25:48.383411Z","iopub.execute_input":"2024-09-05T12:25:48.383778Z","iopub.status.idle":"2024-09-05T12:25:48.392392Z","shell.execute_reply.started":"2024-09-05T12:25:48.383743Z","shell.execute_reply":"2024-09-05T12:25:48.391413Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Attention과 QKV\n\n![content img](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_15_pUfIgKn.png)\n\n- 쿼리(Query):\n\n퀴리는 현재 주목하고 있는 토큰 또는 정보의 표현입니다. 어텐션 메커니즘에서는 퀴리를 사용하여 다른 모든 토큰 또는 정보와의 관계를 평가합니다.\n예를 들어, \"나는 ___ 좋아한다\"라는 문장에서 빈칸을 채우려 할 때, \"나는\"이 퀴리가 될 수 있습니다.\n\n- 키(Key):\n\n키는 다른 모든 토큰 또는 정보의 표현입니다. 퀴리와 각 키 사이의 유사도를 계산하여 어떤 토큰 또는 정보에 주목할지 결정합니다.\n위의 예에서, 가능한 빈칸의 후보들(예: \"사과\", \"축구\", \"노래\") 각각이 키가 될 수 있습니다.\n\n- 값(Value):\n\n값은 키와 연관된 실제 정보나 페이로드입니다. 어텐션 메커니즘에서는 퀴리와 키 사이의 유사도를 기반으로 각 값에 가중치를 부여하고, 이 가중치를 사용하여 가중 평균된 값을 출력합니다.\n위의 예에서, 각 후보에 대한 추가 정보나 설명이 값이 될 수 있습니다.\n\n- 셀프 어텐션(Self attention):\n\n셀프 어텐션은 입력 시퀀스의 각 토큰에 대해 동일한 시퀀스 내의 다른 모든 토큰과의 관계를 계산하는 방식입니다.  \n\n이를 통해 문장 내의 각 단어가 문장의 다른 부분과 어떻게 상호작용하는지를 파악할 수 있습니다.  \n\n셀프 어텐션 연산은 아래와 같이 진행됩니다.  \n\n![content img](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_16_neA52rZ.png)\n\n쿼리(Query), 키(Key), 값(Value) 생성:\n\n1. 먼저, 입력 시퀀스의 각 토큰에 대해 쿼리, 키, 값 표현을 생성합니다. 이는 주어진 입력에 대해 선형 변환을 수행함으로써 이루어집니다.\n\n```\nself.w_q = nn.Linear(d_model, d_model)\nself.w_k = nn.Linear(d_model, d_model)\nself.w_v = nn.Linear(d_model, d_model)\n```\n\n\n2. 어텐션 스코어 계산:\n\n각 쿼리와 모든 키 사이의 유사도(주로 내적)를 계산합니다. 이렇게 계산된 스코어는 어떤 토큰들이 현재 주목하고 있는 토큰과 관련이 깊은지를 나타냅니다.\n\n```\nenergy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n```\n\n3. 스코어 정규화 및 소프트맥스 적용:\n\n계산된 스코어를 정규화합니다. 주로 스코어를 특정 값(예: sqrt(d_model))으로 나누어 스케일링합니다. 그 후, 소프트맥스 함수를 적용하여 각 스코어를 확률 값으로 변환합니다.\n\n```\nattention = self.dropout(self.softmax(energy))\n```\n\n4. 값 가중치 부여 및 합산:\n\n소프트맥스로 얻은 확률 값을 각 값에 곱하여 가중치를 부여합니다. 그런 다음, 모든 가중치가 부여된 값들을 합산하여 셀프 어텐션의 출력을 생성합니다.\n\n```\nx = torch.matmul(attention, V)\n```\n\n5. 출력 선형 변환:\n\n마지막으로, 어텐션 출력을 추가적인 선형 변환을 통해 최종 결과를 얻습니다.\n\n```\nx = self.fc(x)\n```","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:04:33.679788Z","iopub.execute_input":"2024-09-05T12:04:33.680197Z","iopub.status.idle":"2024-09-05T12:04:33.694456Z","shell.execute_reply.started":"2024-09-05T12:04:33.680161Z","shell.execute_reply":"2024-09-05T12:04:33.692966Z"}}},{"cell_type":"markdown","source":"### 3.4 Multihead attention 클래스 선언\n\n트랜스포머 계열의 모델에서 가장 중요한 부분을 꼽으라면, 망설임 없이 멀티 헤드 어텐션 메커니즘이라고 할 수 있습니다.  \n\n멀티 헤드 어텐션은 트랜스포머 아키텍처의 핵심 구성 요소 중 하나로, 셀프 어텐션(Self-Attention) 메커니즘을 여러 번 동시에 수행하는 방식입니다.  \n\n입력 데이터의 다양한 부분에 주목하여 정보를 집계하는 데 사용되며, 특히나 복잡한 패턴과 관계를 학습하는 데 매우 유용합니다\n\n초기화 부분: 쿼리(Q), 키(K), 값(V)에 대한 선형 변환을 정의합니다. 이 변환은 입력 데이터를 여러 '헤드'로 분할하여 각 헤드에서 어텐션을 계산하는 데 사용됩니다.\n\n순전파 부분:\n\n1. 쿼리, 키, 값에 대한 선형 변환을 수행합니다.\n\n2. 멀티 헤드 어텐션을 위해 데이터를 여러 헤드로 분할합니다.\n\n3. 각 헤드에서 어텐션 스코어를 계산하고, 필요한 경우 마스크를 적용합니다.\n\n4. 어텐션 가중치를 계산하고, 이를 사용하여 값 행렬과 곱하여 어텐션 출력을 얻습니다.\n5. 모든 헤드의 출력을 연결하고, 추가적인 선형 변환을 수행합니다.","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # 쿼리, 키, 값에 대한 선형 변환\n        self.w_q = nn.Linear(d_model, d_model)\n        self.w_k = nn.Linear(d_model, d_model)\n        self.w_v = nn.Linear(d_model, d_model)\n\n        # 드롭아웃 적용\n        self.dropout = nn.Dropout(dropout)\n\n        # 멀티 헤드 어텐션 후의 선형 변환\n        self.fc = nn.Linear(d_model, d_model)\n\n        # 스케일링 팩터\n        self.scale = torch.sqrt(torch.FloatTensor([d_model // n_heads])).to(device)\n        # 소프트맥스 함수 정의\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, query, key, value, mask=None):\n        batch_size = query.shape[0]\n\n        # 쿼리, 키, 값에 대한 선형 변환\n        Q = self.w_q(query)\n        K = self.w_k(key)\n        V = self.w_v(value)\n\n        # 멀티 헤드 어텐션을 위한 차원 변환\n        Q = Q.view(batch_size, -1, n_heads, d_model // n_heads).permute(0, 2, 1, 3)\n        K = K.view(batch_size, -1, n_heads, d_model // n_heads).permute(0, 2, 1, 3)\n        V = V.view(batch_size, -1, n_heads, d_model // n_heads).permute(0, 2, 1, 3)\n\n        # 어텐션 스코어 계산\n        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n\n        # 마스크 적용\n        if mask is not None:\n            energy = energy.masked_fill(mask == 0, -1e10)\n\n        # 소프트맥스 함수를 통해 어텐션 가중치 계산\n        attention = self.dropout(self.softmax(energy))\n\n        # 어텐션 가중치와 값 행렬을 곱하여 출력 계산\n        x = torch.matmul(attention, V)\n        x = x.permute(0, 2, 1, 3).contiguous()\n        x = x.view(batch_size, -1, d_model)\n\n        # 최종 선형 변환\n        x = self.fc(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:25:50.481324Z","iopub.execute_input":"2024-09-05T12:25:50.481966Z","iopub.status.idle":"2024-09-05T12:25:50.493348Z","shell.execute_reply.started":"2024-09-05T12:25:50.481927Z","shell.execute_reply":"2024-09-05T12:25:50.492413Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # 쿼리, 키, 값에 대한 선형 변환\n        # Your code\n\n        # 드롭아웃 적용\n        self.dropout = nn.Dropout(dropout)\n\n        # 멀티 헤드 어텐션 후의 선형 변환\n        self.fc = nn.Linear(d_model, d_model)\n\n        # 스케일링 팩터\n        self.scale = torch.sqrt(torch.FloatTensor([d_model // n_heads])).to(device)\n        # 소프트맥스 함수 정의\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, query, key, value, mask=None):\n        batch_size = query.shape[0]\n\n        # 쿼리, 키, 값에 대한 선형 변환\n        # Your code\n\n\n        # 멀티 헤드 어텐션을 위한 차원 변환\n        Q = Q.view(batch_size, -1, n_heads, d_model // n_heads).permute(0, 2, 1, 3)\n        K = K.view(batch_size, -1, n_heads, d_model // n_heads).permute(0, 2, 1, 3)\n        V = V.view(batch_size, -1, n_heads, d_model // n_heads).permute(0, 2, 1, 3)\n\n        # 어텐션 스코어 계산\n        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n\n        # 마스크 적용\n        if mask is not None:\n            energy = energy.masked_fill(mask == 0, -1e10)\n\n        # 소프트맥스 함수를 통해 어텐션 가중치 계산\n        # Your code\n\n\n        # 어텐션 가중치와 값 행렬을 곱하여 출력 계산\n        x = torch.matmul(attention, V)\n        x = x.permute(0, 2, 1, 3).contiguous()\n        x = x.view(batch_size, -1, d_model)\n\n        # 최종 선형 변환\n        x = self.fc(x)\n\n        return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"중간에 멀티 헤드 어텐션을 위해 차원을 변환하는 과정이 있습니다.\n\n`permute()`는 텐서의 차원을 재배열하는 함수로, 여기서 `permute(0, 2, 1, 3)`를 사용하는 이유는 멀티 헤드 어텐션을 계산하기 위해 텐서의 차원을 적절하게 재배열하기 위함입니다.\n\n원래 텐서의 차원은 `[batch_size, seq_len, n_heads, d_model // n_heads]`입니다. 여기서:\n\n- `batch_size`: 배치 크기\n\n- `seq_len`: 시퀀스 길이\n\n- `n_heads`: 어텐션 헤드의 수\n\n- `d_model`: 모델의 차원\n\npermute(0, 2, 1, 3)를 사용하면 차원의 순서가 [batch_size, n_heads, seq_len, d_model // n_heads]로 변경됩니다.  \n\n이렇게 차원을 재배열하면, 각 어텐션 헤드는 독립적으로 시퀀스에 대한 어텐션을 계산할 수 있습니다. 그리고 이렇게 계산된 결과를 다시 원래의 차원 순서로 변경하여 최종 결과를 얻을 수 있습니다.\n","metadata":{}},{"cell_type":"markdown","source":"### 3.5 Positionwise Feedforward Network\n\nPositionwiseFeedforward 네트워크는 트랜스포머 아키텍처의 각 인코더와 디코더 레이어에 포함되어 있습니다. 이 네트워크는 기본적으로 두 개의 선형 변환을 연속적으로 적용하는데, 여기서는 1D Convolution을 사용하여 이 변환을 수행합니다.\n\n![](https://miro.medium.com/max/1906/1*1l5JbeGfEGh2oxjI8koHdQ.png)\n\n초기화 부분: 두 개의 1D Conv 레이어를 정의합니다. 첫 번째 합성곱은 `d_model` 차원의 입력을 `d_ff` 차원으로 확장하고, 두 번째 합성곱은 그 결과를 다시 `d_model` 차원으로 축소합니다.\n\n순전파 부분:\n\n1. 입력 x의 차원을 변경하여 Convolution을 적용하기 적합한 형태로 만듭니다.\n\n2. 첫 번째 합성곱 레이어와 GELU 활성화 함수를 적용한 후, 결과에 드롭아웃을 적용합니다.\n\n3. 두 번째 Convolution 레이어를 적용합니다.\n\n4. 결과의 차원을 원래대로 변경하여 출력합니다.\n\n이 네트워크는 멀티헤드 어텐션의 출력에 비선형 변환을 추가하여 모델의 표현력을 높이는 역할을 합니다.","metadata":{}},{"cell_type":"code","source":"class PositionwiseFeedforward(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # 1D Convolution을 사용하여 선형 변환을 수행\n        self.fc1 = nn.Conv1d(d_model, d_ff, 1)\n        self.fc2 = nn.Conv1d(d_ff, d_model, 1)\n\n        # 드롭아웃 정의\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # 입력 x의 차원을 변경\n        x = x.permute(0, 2, 1)\n\n        # 첫 번째 Convolution과 활성화 함수 적용 후 드롭아웃\n        x = self.dropout(gelu(self.fc1(x)))\n\n        # 두 번째 Convolution 적용\n        x = self.fc2(x)\n\n        # 차원을 원래대로 변경하여 출력\n        x = x.permute(0, 2, 1)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:25:54.242454Z","iopub.execute_input":"2024-09-05T12:25:54.243205Z","iopub.status.idle":"2024-09-05T12:25:54.249939Z","shell.execute_reply.started":"2024-09-05T12:25:54.243144Z","shell.execute_reply":"2024-09-05T12:25:54.249033Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class PositionwiseFeedforward(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # 1D Convolution을 사용하여 선형 변환을 수행\n        self.fc1 = nn.Conv1d(d_model, d_ff, 1)\n        self.fc2 = nn.Conv1d(d_ff, d_model, 1)\n\n        # 드롭아웃 정의\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # 입력 x의 차원을 변경\n        x = x.permute(0, 2, 1)\n\n        # 첫 번째 Convolution과 활성화 함수 적용 후 드롭아웃\n        # Your code\n\n        # 두 번째 Convolution 적용\n        # Your code\n\n        # 차원을 원래대로 변경하여 출력\n        x = x.permute(0, 2, 1)\n\n        return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.6 Encoder layer\n\n트랜스포머 아키텍처의 인코더 레이어를 구현한 클래스입니다.  \n\n![content img](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_22_teJgoCi.max-800x600.png)\n\n각 인코더 레이어는 앞서 선언한 두 가지 주요 구성 요소로 이루어져 있습니다:\n- 멀티 헤드 셀프 어텐션\n\n- Position-wise feedforward network\n\n초기화 부분:\n\n- `MultiHeadAttention`: 멀티헤드 셀프 어텐션을 수행합니다. 이는 입력 시퀀스 내의 각 토큰이 다른 모든 토큰과 어떻게 상호작용하는지를 파악합니다.\n\n- `PositionwiseFeedforward`: 네트워크를 통해 추가적인 비선형 변환을 수행합니다.\n\n- `LayerNorm`: 레이어 정규화는 각 레이어의 출력을 안정화하여 학습을 도와줍니다.\n\n- `Dropout`: 과적합을 방지하기 위한 드롭아웃입니다.\n\n순전파 부분:\n\n- 멀티헤드 셀프 어텐션을 적용한 후, 그 결과와 원래의 입력을 더하고 레이어 정규화를 수행합니다. (잔여 연결 및 레이어 정규화)\n\n- Position-wise Feed forward를 적용한 후, 그 결과와 이전 단계의 출력을 더하고 다시 레이어 정규화를 수행합니다.\n\n이 구조는 BERT 인코더의 각 레이어에서 반복적으로 사용되며, 여러 레이어를 쌓아 복잡한 패턴과 관계를 학습할 수 있게 합니다.\n","metadata":{}},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.encoder_self_attn = MultiHeadAttention()\n        self.encoder_feed_fwd = PositionwiseFeedforward()\n        self.layer_norm = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n\n\n    def forward(self, input, input_mask=None):\n        # input => [batch_size, seq_len, d_model]\n\n        encoder_outputs = self.layer_norm(input + self.dropout(self.encoder_self_attn(input, input, input, input_mask)))\n        encoder_outputs = self.layer_norm(encoder_outputs + self.dropout(self.encoder_feed_fwd(encoder_outputs)))\n        return encoder_outputs","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:25:59.385069Z","iopub.execute_input":"2024-09-05T12:25:59.386059Z","iopub.status.idle":"2024-09-05T12:25:59.392715Z","shell.execute_reply.started":"2024-09-05T12:25:59.386016Z","shell.execute_reply":"2024-09-05T12:25:59.391670Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.encoder_self_attn = MultiHeadAttention()\n        self.encoder_feed_fwd = PositionwiseFeedforward()\n        self.layer_norm = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n\n        \n    def forward(self, input, input_mask=None):\n        # input => [batch_size, seq_len, d_model]\n        \n        # Your code\n        \"\"\"\n        1. encoder self attention\n        2. dropout\n        3. skip connection\n        4. layer norm\n        \"\"\"\n        \n        # Your code\n        \"\"\"\n        1. encoder feed forward\n        2. dropout\n        3. skip connection\n        4. layer norm\n        \"\"\"\n        \n        \n        return encoder_outputs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.7 이번 실습에서 사용된 BERT와 원본 모델과의 차이\n\n이번 실습은 분류에 포커스가 맞춰져있기에, 원본 모델과 다소 차이가 있습니다.\n\n1. PositionwiseFeedforward:\n\n원본 모델에서는 Linear layer(Fully-connected layer)을 통해 연산하지만, 이번 실습에서는 1D Convolution layer를 통해 이 부분을 대체합니다.  \n\n1D Convolution layer을 사용하면 시계열의 특성을 자세하게 읽어낼 수 있을 뿐만 아니라, Linear layer에 비해 적은 파라미터로 연산할 수 있습니다.\n\n2. 모델 출력부분 차이\n\n원본 BERT 모델은 주로 두 가지 출력을 제공합니다:\n\n- Sequence Output: 입력 토큰의 각각에 대한 출력을 포함하는 것으로, 이것은 다운스트림 태스크(예: 토큰 수준의 분류)에 사용될 수 있습니다.\n\n- Pooled Output: 첫 번째 토큰([CLS])에 대한 출력으로, 문장 수준의 분류와 같은 다운스트림 태스크에 주로 사용됩니다. 이 출력은 추가적인 dense layer와 tanh 활성화 함수를 통해 얻어집니다.\n\n실습 모델의 출력은 `Pooled_output`에 추가적 변환 없이 바로 사용합니다.:\n\n- 이 모델에서는 BERT의 인코더 부분을 사용하고, 마지막에 분류 작업을 위한 선형 레이어를 추가하였습니다.\n\n- pooled_output = encoder_output[:, 0]: 이 부분은 BERT의 [CLS] 토큰에 해당하는 출력을 가져옵니다. 그러나 원래 BERT에서처럼 추가적인 dense layer와 tanh 활성화 함수를 사용하지 않습니다.\n\n- output = self.classifier(pooled_output): 이 부분은 문장 수준의 분류를 위한 출력을 생성합니다.","metadata":{}},{"cell_type":"markdown","source":"### 3.8 BERT 클래스 선언\n\n자 이제 필요한 클래스와 함수를 모두 선언하였습니다.\n\n위 내용들을 바탕으로 BERT 모델을 클래스로 선언하겠습니다.  \n\n초기화 부분:\n\n- `Embedding`: 주어진 단어나 토큰을 벡터 형태로 변환하는 임베딩 레이어입니다.\n\n- `layers`: BERT 모델의 핵심 부분인 인코더 레이어들의 리스트입니다. 각 레이어는 멀티헤드 어텐션과 Position-wise Feedforward 네트워크를 포함합니다.\n\n- `linear, activn, norm`: 추가적인 변환을 위한 레이어와 활성화 함수입니다.\n\n- classifier: 문장의 전체적인 표현을 기반으로 최종 출력을 생성하는 분류기입니다.\n\n순전파 부분:\n\n- 입력 `input_ids`는 `Embedding` 레이어를 통과하여 임베딩 벡터로 변환됩니다.\n\n- 임베딩 출력은 순차적으로 각 `EncoderLayer`를 통과하며, 각 레이어에서는 멀티헤드 어텐션과 Position-wise Feedforward 연산이 수행됩니다.\n\n- 모든 인코더 레이어를 통과한 후, 첫 번째 토큰(보통 `[CLS]` 토큰)의 출력만을 사용하여 문장의 전체적인 표현을 얻습니다.\n\n- 이 표현은 `classifier`를 통과하여 최종 출력을 생성합니다.","metadata":{}},{"cell_type":"code","source":"# BERT 모델 정의\nclass BERT(nn.Module):\n    def __init__(self, vocab_size):\n        super().__init__()\n\n        # 임베딩 레이어: 토큰을 벡터로 변환\n        self.embedding = Embedding(vocab_size)\n        # 인코더 레이어들의 리스트\n        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n\n        # 추가적인 선형 변환\n        self.linear = nn.Linear(d_model, d_model)\n        # 활성화 함수로 GELU 사용\n        self.activn = gelu\n        # 레이어 정규화\n        self.norm = nn.LayerNorm(d_model)\n\n        # 최종 분류를 위한 선형 레이어\n        self.classifier = nn.Linear(d_model, 1)\n\n    def forward(self, input_ids, attention_mask):\n        # 임베딩 레이어를 통과\n        embedding_output = self.embedding(input_ids)\n        # 각 인코더 레이어를 순차적으로 통과\n        for layer in self.layers:\n            encoder_output = layer(embedding_output)\n        # 첫 번째 토큰의 출력만 사용하여 문장의 전체적인 표현을 얻음\n        pooled_output = encoder_output[:, 0]\n        # 분류를 위해 선형 레이어를 통과\n        output = self.classifier(pooled_output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:26:01.972084Z","iopub.execute_input":"2024-09-05T12:26:01.972479Z","iopub.status.idle":"2024-09-05T12:26:01.980288Z","shell.execute_reply.started":"2024-09-05T12:26:01.972440Z","shell.execute_reply":"2024-09-05T12:26:01.979342Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# BERT 모델 정의\nclass BERT(nn.Module):\n    def __init__(self, vocab_size):\n        super().__init__()\n\n        # 임베딩 레이어: 토큰을 벡터로 변환\n        # Your code\n        \n        # 인코더 레이어들의 리스트\n        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n\n        # 추가적인 선형 변환\n        self.linear = nn.Linear(d_model, d_model)\n        # 활성화 함수로 GELU 사용\n        self.activn = gelu\n        # 레이어 정규화\n        self.norm = nn.LayerNorm(d_model)\n\n        # 최종 분류를 위한 선형 레이어\n        self.classifier = nn.Linear(d_model, 1)\n\n    def forward(self, input_ids, attention_mask):\n        # 임베딩 레이어를 통과\n        \n        # Your code\n        \n        # 각 인코더 레이어를 순차적으로 통과\n        \n        # Your code\n        \n        # 첫 번째 토큰의 출력만 사용하여 문장의 전체적인 표현을 얻음\n        \n        pooled_output = encoder_output[:, 0]\n        \n        # 분류를 위해 선형 레이어를 통과\n        \n        # Your code\n        return ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.9 모델 인스턴스화\n\n클래스를 바탕으로 모델 인스턴스를 생성해봅시다.  \n\n- `BERT(vocab_size)`: 주어진 어휘 크기를 사용하여 BERT 모델을 초기화합니다.\n\n`model.to(device)`: 모델을 지정된 디바이스로 이동시킵니다. device는 보통 GPU를 의미하며, GPU에서 모델을 학습하려는 경우 이 코드를 사용하여 데이터와 모델을 GPU로 전송해야합니다.\n\n`nn.BCEWithLogitsLoss()`: 이번 실습은 리뷰에 대한 긍･부정 평가입니다. 이진 분류 문제를 위한 손실 함수입니다. 로짓을 입력으로 받아 이진 교차 엔트로피 손실을 계산합니다.\n\n`optim.Adam(model.parameters(), lr=lr)`: Adam 옵티마이저를 초기화합니다. 옵티마이저는 모델의 파라미터를 업데이트하는 데 사용됩니다.\n\n`print(model)`: 초기화된 BERT 모델의 구조를 출력합니다.\n\n","metadata":{}},{"cell_type":"code","source":"# BERT 모델 초기화\nmodel = BERT(vocab_size)\n# 모델을 지정된 디바이스로 이동(GPU)\nmodel = model.to(device)\n# 손실 함수로 Binary Cross Entropy with Logits Loss 사용\ncriterion = nn.BCEWithLogitsLoss()\n# 최적화 도구로 Adam 사용\noptimizer = optim.Adam(model.parameters(), lr=lr)\n\n# 모델 구조 출력\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:26:05.415673Z","iopub.execute_input":"2024-09-05T12:26:05.416516Z","iopub.status.idle":"2024-09-05T12:26:07.374917Z","shell.execute_reply.started":"2024-09-05T12:26:05.416475Z","shell.execute_reply":"2024-09-05T12:26:07.374007Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"BERT(\n  (embedding): Embedding(\n    (tok_embedding): Embedding(20000, 768)\n    (pos_embedding): Embedding(512, 768)\n    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (layers): ModuleList(\n    (0-11): 12 x EncoderLayer(\n      (encoder_self_attn): MultiHeadAttention(\n        (w_q): Linear(in_features=768, out_features=768, bias=True)\n        (w_k): Linear(in_features=768, out_features=768, bias=True)\n        (w_v): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (fc): Linear(in_features=768, out_features=768, bias=True)\n        (softmax): Softmax(dim=-1)\n      )\n      (encoder_feed_fwd): PositionwiseFeedforward(\n        (fc1): Conv1d(768, 3072, kernel_size=(1,), stride=(1,))\n        (fc2): Conv1d(3072, 768, kernel_size=(1,), stride=(1,))\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (linear): Linear(in_features=768, out_features=768, bias=True)\n  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (classifier): Linear(in_features=768, out_features=1, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_and_validate(model, train_dataloader, validation_dataloader, epochs, optimizer, criterion):\n    # 전체 에포크만큼 학습 및 검증 반복\n    for epoch in range(epochs):\n        print(f'Epoch {epoch+1}/{epochs}')\n        print('-' * 10)\n\n        # 학습 모드 설정\n        model.train()\n        total_loss = 0\n        train_preds, train_labels = [], []\n\n        # 학습 데이터로 학습 진행\n        progress_bar = tqdm(train_dataloader, desc='Training', position=0, leave=True)\n        for step, batch in enumerate(progress_bar):\n            # 배치 데이터를 디바이스에 할당\n            b_input_ids = batch[0].to(device)\n            b_input_mask = batch[1].to(device)\n            b_labels = batch[2].to(device)\n\n            # 그래디언트 초기화\n            model.zero_grad()\n\n            # 모델에 입력 데이터 전달 및 출력 얻기\n            outputs = model(b_input_ids, b_input_mask)\n\n            # 손실 계산\n            loss = criterion(outputs.squeeze(), b_labels.float())\n            total_loss += loss.item()\n\n            # 그래디언트 계산\n            loss.backward()\n\n            # 그래디언트 클리핑\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            # 파라미터 업데이트\n            optimizer.step()\n\n            # 예측값 및 레이블 저장\n            train_preds.extend(torch.sigmoid(outputs).squeeze().detach().cpu().numpy().tolist())\n            train_labels.extend(b_labels.squeeze().detach().cpu().numpy().tolist())\n\n            # 진행 바 업데이트\n            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n\n        # 평균 학습 손실 출력\n        avg_train_loss = total_loss / len(train_dataloader)\n        print(\"\\nAverage training loss: {0:.2f}\".format(avg_train_loss))\n\n        # 학습 정확도 계산 및 출력\n        train_preds = [1 if pred > 0.5 else 0 for pred in train_preds]\n        train_acc = accuracy_score(train_labels, train_preds)\n        print(\"Training Accuracy: {0:.2f}\".format(train_acc))\n\n        # 검증 모드 설정\n        model.eval()\n        total_eval_loss = 0\n        val_preds, val_labels = [], []\n\n        # 검증 데이터로 검증 진행\n        progress_bar = tqdm(validation_dataloader, desc='Validation', position=0, leave=True)\n        for batch in progress_bar:\n            # 배치 데이터를 디바이스에 할당\n            b_input_ids = batch[0].to(device)\n            b_input_mask = batch[1].to(device)\n            b_labels = batch[2].to(device)\n\n            # 그래디언트 계산 비활성화\n            with torch.no_grad():\n                # 모델에 입력 데이터 전달 및 출력 얻기\n                outputs = model(b_input_ids, b_input_mask)\n\n            # 손실 계산\n            loss = criterion(outputs.squeeze(), b_labels.float())\n            total_eval_loss += loss.item()\n\n            # 예측값 및 레이블 저장\n            val_preds.extend(torch.sigmoid(outputs).squeeze().detach().cpu().numpy().tolist())\n            val_labels.extend(b_labels.squeeze().detach().cpu().numpy().tolist())\n\n            # 진행 바 업데이트\n            progress_bar.set_postfix({'validation_loss': '{:.3f}'.format(loss.item()/len(batch))})\n\n        # 평균 검증 손실 출력\n        avg_val_loss = total_eval_loss / len(validation_dataloader)\n        print(\"\\nAverage validation loss: {0:.2f}\".format(avg_val_loss))\n\n        # 검증 정확도 계산 및 출력\n        val_preds = [1 if pred > 0.5 else 0 for pred in val_preds]\n        val_acc = accuracy_score(val_labels, val_preds)\n        print(\"Validation Accuracy: {0:.2f}\".format(val_acc))","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:26:08.788809Z","iopub.execute_input":"2024-09-05T12:26:08.789569Z","iopub.status.idle":"2024-09-05T12:26:08.807033Z","shell.execute_reply.started":"2024-09-05T12:26:08.789529Z","shell.execute_reply":"2024-09-05T12:26:08.806048Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# 학습 시작\ntrain_and_validate(model, train_dataloader, validation_dataloader, epochs, optimizer, criterion)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T12:26:09.727966Z","iopub.execute_input":"2024-09-05T12:26:09.728362Z","iopub.status.idle":"2024-09-05T12:30:43.578128Z","shell.execute_reply.started":"2024-09-05T12:26:09.728321Z","shell.execute_reply":"2024-09-05T12:30:43.577143Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/5\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 319/319 [00:51<00:00,  6.20it/s, training_loss=0.081]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage training loss: 0.42\nTraining Accuracy: 0.81\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 36/36 [00:04<00:00,  8.42it/s, validation_loss=0.168]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage validation loss: 0.37\nValidation Accuracy: 0.83\nEpoch 2/5\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 319/319 [00:50<00:00,  6.36it/s, training_loss=0.114]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage training loss: 0.35\nTraining Accuracy: 0.85\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 36/36 [00:04<00:00,  8.49it/s, validation_loss=0.171]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage validation loss: 0.36\nValidation Accuracy: 0.85\nEpoch 3/5\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 319/319 [00:50<00:00,  6.34it/s, training_loss=0.119]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage training loss: 0.32\nTraining Accuracy: 0.86\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 36/36 [00:04<00:00,  8.47it/s, validation_loss=0.176]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage validation loss: 0.36\nValidation Accuracy: 0.85\nEpoch 4/5\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 319/319 [00:50<00:00,  6.35it/s, training_loss=0.119]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage training loss: 0.30\nTraining Accuracy: 0.87\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 36/36 [00:04<00:00,  8.50it/s, validation_loss=0.116]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage validation loss: 0.32\nValidation Accuracy: 0.86\nEpoch 5/5\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 319/319 [00:50<00:00,  6.34it/s, training_loss=0.078]\n","output_type":"stream"},{"name":"stdout","text":"\nAverage training loss: 0.29\nTraining Accuracy: 0.87\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 36/36 [00:04<00:00,  8.50it/s, validation_loss=0.149]","output_type":"stream"},{"name":"stdout","text":"\nAverage validation loss: 0.35\nValidation Accuracy: 0.85\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}