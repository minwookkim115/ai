{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSVzmRVLJrwm"
      },
      "source": [
        "# 신경망 구조"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F8W4x9kembv"
      },
      "source": [
        "## 퍼셉트론\n",
        "\n",
        "- 인공신경망의 한 종류\n",
        "- 다수의 입력($x_1, x_2, ..., x_n$)과 가중치($w_1, w_2, ..., w_n$)를 곱하여 그 값에 편향($bias$)을 더한 값이 어느 임계치 값($\\theta$)을 초과하면 활성화 함수를 통과한 출력값을 내보냄\n",
        "![perceptron](https://miro.medium.com/max/1400/1*ofVdu6L3BDbHyt1Ro8w07Q.png)\n",
        "<br /><sub>출처: https://towardsdatascience.com/rosenblatts-perceptron-the-very-first-neural-network-37a3ec09038a</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxALA-qreoJ-"
      },
      "source": [
        "## 뉴런의 수학적 표현\n",
        "\n",
        "![](https://cs231n.github.io/assets/nn1/neuron_model.jpeg)\n",
        "<br /><sub>출처: https://cs231n.github.io/convolutional-networks/</sub>\n",
        "\n",
        "$\\qquad y = f(\\sum_{i} w_ix_i + b) \\quad $\n",
        "\n",
        "  - $f\\ $ : 활성화 함수\n",
        "    - 임계값($\\theta$)을 경계로 출력이 바뀜\n",
        "\n",
        "  - $b\\ \\ $ :  편향\n",
        "    - <u>결정 경계선을 원점에서부터 벗어나게 해줌</u>\n",
        "    - 따로 표현이 없어도 기본적으로 존재한다고 생각\n",
        "\n",
        "  - $\\sum_{i} w_ix_i$ :$\\quad $두 벡터의 내적으로 표현 가능\n",
        "     \n",
        "     $\\\\ \\quad x_1w_1 + x_2w_2 +\\ ... \\ + x_nw_n = w^Tx$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl6DMX9Yetsv"
      },
      "source": [
        "\n",
        "## 완전 연결 계층(Fully-Connected Layer) 수학적 표현\n",
        "\n",
        "![](https://miro.medium.com/max/620/1*ZBYO3waYUyPsLm0rb15sEQ.png)\n",
        "<br /><sub>출처: https://towardsdatascience.com/the-sparse-future-of-deep-learning-bce05e8e094a</sub>\n",
        "\n",
        "  $\\qquad  W = [w_0, w_1,\\ ..., \\ w_{M-1}]^T $  \n",
        "  $\\qquad $  각각의 $w_k$는 $N\\times 1$ 형태의 벡터  \n",
        "  $\\qquad W$는 $N \\times M$ 행렬\n",
        "\n",
        "  $ \\qquad b$ = $[b_0, b_1, \\ ..., \\ b_{M-1}]$  \n",
        "\n",
        "  $\\qquad y_0 = f(w_0^Tx + b_0)$  \n",
        "\n",
        "  $\\qquad y_1 = f(w_1^Tx + b_1)$  \n",
        "\n",
        "  $\\qquad y_2 = f(w_2^Tx + b_2)$  \n",
        "  \n",
        "  $\\qquad \\quad ...$\n",
        "\n",
        "  $\\qquad y_{M-1} = f(w_{M-1}^Tx + b_{M-1})$  \n",
        "\n",
        "  $\\quad  \\rightarrow y = f(Wx + b)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH7jWsHRewUi"
      },
      "source": [
        "## 논리회로\n",
        "  * 논리 게이트(Logic Gates)\n",
        "    - AND\n",
        "    - OR\n",
        "    - NOT\n",
        "    - NAND\n",
        "    - NOR  \n",
        "\n",
        "* 다이어그램과 진리표\n",
        "\n",
        "![](http://www.schoolphysics.co.uk/age14-16/Electronics/text/Logic_gates/images/1.png)\n",
        "<br /><sub>출처: http://www.schoolphysics.co.uk/age14-16/Electronics/text/Logic_gates/index.html</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3pY4J8MezBm"
      },
      "source": [
        "### AND 게이트\n",
        "\n",
        "- 두 입력이 모두 1일 때 1을 출력하는 논리회로   \n",
        "\n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/and_logic.jpg)\n",
        "\n",
        "- 진리표\n",
        "\n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/and_truthtable.jpg)\n",
        "<br /><sub>출처: https://www.tutorialspoint.com/computer_logical_organization/logic_gates.htm</sub>\n",
        "\n",
        "- AND 게이트를 만족시키는 가중치와 편향 구하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml6u-oCzenlh"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQHe-5E2e2UJ"
      },
      "source": [
        "def AND(a, b):\n",
        "  input = np.array([a, b])\n",
        "  weights = np.array([0.5, 0.5])\n",
        "  bias = -0.7\n",
        "  value = np.sum(input * weights) + bias\n",
        "\n",
        "  if value <= 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gObrhki8e4hk"
      },
      "source": [
        "print(AND(0, 0))\n",
        "print(AND(0, 1))\n",
        "print(AND(1, 0))\n",
        "print(AND(1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDPqdCl1e6fV"
      },
      "source": [
        "x1 = np.arange(-2, 2, 0.01)\n",
        "x2 = np.arange(-2, 2, 0.01)\n",
        "bias = -0.7\n",
        "\n",
        "y = (-0.4 * x1 - bias) / 0.4\n",
        "\n",
        "plt.axvline(x=0)\n",
        "plt.axhline(y=0)\n",
        "\n",
        "plt.plot(x1, y, 'r--')\n",
        "plt.scatter(0,0, color='orange', marker='o', s=150)\n",
        "plt.scatter(0,1, color='orange', marker='o', s=150)\n",
        "plt.scatter(1,0, color='orange', marker='o', s=150)\n",
        "plt.scatter(1,1, color='black', marker='^', s=150)\n",
        "plt.xlim(-0.5, 1.5)\n",
        "plt.ylim(-0.5, 1.5)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gz29P-ve-jD"
      },
      "source": [
        "### OR 게이트\n",
        "\n",
        "- 두 입력 중 하나라도 1이면 1을 출력하는 논리회로  \n",
        "  \n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/or_logic.jpg)\n",
        "\n",
        "- 진리표  \n",
        "\n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/or_truthtable.jpg)\n",
        "<br /><sub>출처: https://www.tutorialspoint.com/computer_logical_organization/logic_gates.htm</sub>\n",
        "\n",
        "- OR 게이트를 만족시키는 가중치와 편향 구하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mSvmfXve8JR"
      },
      "source": [
        "def OR(a, b):\n",
        "  input = np.array([a, b])\n",
        "  weights = np.array([0.4, 0.5])\n",
        "  bias = -0.3\n",
        "  value = np.sum(input * weights) + bias\n",
        "\n",
        "  if value <= 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xc_nF6lfNH3"
      },
      "source": [
        "print(OR(0, 0))\n",
        "print(OR(0, 1))\n",
        "print(OR(1, 0))\n",
        "print(OR(1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR9RrNj4fOez"
      },
      "source": [
        "x1 = np.arange(-2, 2, 0.01)\n",
        "x2 = np.arange(-2, 2, 0.01)\n",
        "bias = -0.3\n",
        "\n",
        "y = (-0.4 * x1 - bias) / 0.5\n",
        "\n",
        "plt.axvline(x=0)\n",
        "plt.axhline(y=0)\n",
        "\n",
        "plt.plot(x1, y, 'r--')\n",
        "plt.scatter(0,0, color='black', marker='^', s=150)\n",
        "plt.scatter(0,1, color='orange', marker='o', s=150)\n",
        "plt.scatter(1,0, color='orange', marker='o', s=150)\n",
        "plt.scatter(1,1, color='orange', marker='o', s=150)\n",
        "plt.xlim(-0.5, 1.5)\n",
        "plt.ylim(-0.5, 1.5)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3anpbTsfR7A"
      },
      "source": [
        "### NAND 게이트\n",
        "\n",
        "\n",
        "- 두 입력이 모두 1일 때 0을 출력하는 논리회로\n",
        "\n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/nand_logic.jpg)\n",
        "\n",
        "- 진리표  \n",
        "\n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/nand_truthtable.jpg)\n",
        "<br /><sub>출처: https://www.tutorialspoint.com/computer_logical_organization/logic_gates.htm</sub>\n",
        "\n",
        "- NAND 게이트를 만족시키는 가중치와 편향 구하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJP5BLDGfP4-"
      },
      "source": [
        "def NAND(a, b):\n",
        "  input = np.array([a, b])\n",
        "  weights = np.array([-0.6, -0.5])\n",
        "  bias = 0.7\n",
        "  value = np.sum(input * weights) + bias\n",
        "\n",
        "  if value <= 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juB8y1zIfY7z"
      },
      "source": [
        "print(NAND(0, 0))\n",
        "print(NAND(0, 1))\n",
        "print(NAND(1, 0))\n",
        "print(NAND(1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6WDqUWefaeX"
      },
      "source": [
        "x1 = np.arange(-2, 2, 0.01)\n",
        "x2 = np.arange(-2, 2, 0.01)\n",
        "bias = 0.7\n",
        "\n",
        "y = (0.6 * x1 - bias) / -0.5\n",
        "\n",
        "plt.axvline(x=0)\n",
        "plt.axhline(y=0)\n",
        "\n",
        "plt.plot(x1, y, 'r--')\n",
        "plt.scatter(0,0, color='black', marker='o', s=150)\n",
        "plt.scatter(0,1, color='black', marker='o', s=150)\n",
        "plt.scatter(1,0, color='black', marker='o', s=150)\n",
        "plt.scatter(1,1, color='orange', marker='^', s=150)\n",
        "plt.xlim(-0.5, 1.5)\n",
        "plt.ylim(-0.5, 1.5)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWVJN3iTfenX"
      },
      "source": [
        "### XOR 게이트\n",
        "\n",
        "- 인공지능 첫번째 겨울\n",
        "- 딥러닝의 첫번째 위기를 초래\n",
        "  - 마빈 민스키와 세이무어 페퍼트에 의해 문제 제기\n",
        "  - AND, NAND와 같은 선형문제는 퍼셉트론으로 해결 가능, 하지만 XOR은 어떻게? 직선(선형) 하나로는 불가능!\n",
        "\n",
        "![](http://ecee.colorado.edu/~ecen4831/lectures/xor2.gif)\n",
        "<br /><sub>출처: http://ecee.colorado.edu/~ecen4831/lectures/NNet3.html</sub>\n",
        "\n",
        "- **다층 퍼셉트론**으로 해결\n",
        "  - 비선형 문제를 해결할 수 있다!\n",
        "\n",
        "- AND, NAND, OR Gate를 조합"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7hNassAfhxK"
      },
      "source": [
        "## 다층 퍼셉트론(Multi Layer Perceptron, MLP)  \n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/c/c2/MultiLayerNeuralNetworkBigger_english.png)\n",
        "<br /><sub>출처: https://commons.wikimedia.org/wiki/File:MultiLayerNeuralNetworkBigger_english.png</sub>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N6uSU0-L4Oi"
      },
      "source": [
        "### 다층 퍼셉트론의 구성\n",
        "\n",
        "  - 입력층(input layer)\n",
        "  - 은닉층(hidden layer)\n",
        "    - 1개 이상 존재\n",
        "    - 보통 5개 이상 존재하면 Deep Neural Network라고 칭함\n",
        "  - 출력층(output layer)  \n",
        "\n",
        "![](https://www.researchgate.net/profile/Sandip_Lahiri/publication/26614896/figure/fig1/AS:310007494135809@1450922954279/A-schematic-diagram-of-artificial-neural-network-and-architecture-of-the-feed-forward.png)\n",
        "<br /><sub>출처: https://www.researchgate.net/figure/A-schematic-diagram-of-artificial-neural-network-and-architecture-of-the-feed-forward_fig1_26614896</sub>\n",
        "\n",
        "  - 수식\n",
        "\n",
        "    - (input layer $\\rightarrow$ hidden layer)   \n",
        "  $ \\quad z = f_L(W_Lx + b_L) $  \n",
        "\n",
        "    - (hidden layer $\\rightarrow$ output layer)   \n",
        "  $ \\quad y = a_K(W_Kz + b_K) $  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38mOWdHzfsO_"
      },
      "source": [
        "### XOR 게이트\n",
        "- 서로 다른 두 값이 입력으로 들어가면 1을 반환\n",
        "\n",
        "- 진리표  \n",
        "\n",
        "![](https://www.tutorialspoint.com/computer_logical_organization/images/xor_truthtable.jpg)\n",
        "<br /><sub>출처: https://www.tutorialspoint.com/computer_logical_organization/logic_gates.htm</sub>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VULVZbxVfb_M"
      },
      "source": [
        "def XOR(x1, x2):\n",
        "  s1 = NAND(x1, x2)\n",
        "  s2 = OR(x1, x2)\n",
        "  y = AND(s1, s2)\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFcXlWJKfuLg"
      },
      "source": [
        "print(XOR(0, 0))\n",
        "print(XOR(0, 1))\n",
        "print(XOR(1, 0))\n",
        "print(XOR(1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgdNIo5dfx2Y"
      },
      "source": [
        "## 활성화 함수(Activation Function)\n",
        "\n",
        "- 입력 신호의 총합을 출력 신호로 변환하는 함수\n",
        "- 활성화 함수에 따라 출력값이 결정\n",
        "- 단층, 다층 퍼셉트론 모두 사용\n",
        "- 대표적인 활성화 함수\n",
        "  - Sigmoid\n",
        "  - ReLU\n",
        "  - tanh\n",
        "  - Identity Function\n",
        "  - Softmax\n",
        "\n",
        "-  하나의 layer에서 다음 layer로 넘어갈 때는 항상 활성화 함수를 통과\n",
        "    \n",
        "- [참고] 여러가지 활성화 함수  \n",
        " https://en.wikipedia.org/wiki/Activation_function  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqLlBrSEf31I"
      },
      "source": [
        "### Step Function(계단 함수)\n",
        "\n",
        "### $\\quad y = \\begin{cases}\n",
        "0 \\quad (x < 0) \\\\\n",
        "1 \\quad (x \\ge 0)\n",
        "\\end{cases} $   \n",
        "\n",
        "![](https://www.intmath.com/laplace-transformation/svg/svgphp-unit-step-functions-definition-1a-s1.svg)\n",
        "<br /><sub>출처: https://www.intmath.com/laplace-transformation/1a-unit-step-functions-definition.php</sub>\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQS9fxpfIZLS"
      },
      "source": [
        "def step_function(x):\n",
        "  if x > 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9wJ-Ht1fvpi"
      },
      "source": [
        "def step_function_for_numpy(x):\n",
        "  y = x > 0\n",
        "  return y.astype(np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eYjdSmUf5zm"
      },
      "source": [
        "print(step_function(-3))\n",
        "print(step_function(5))\n",
        "\n",
        "a = np.array([5, 3, -4, 2.0])\n",
        "print(step_function_for_numpy(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OKFVCMqf9uc"
      },
      "source": [
        "\n",
        "### Sigmoid Function(시그모이드 함수)\n",
        "- 이진분류(binary classification)에 주로 사용\n",
        "  - 마지막 출력층의 활성화 함수로 사용\n",
        "- 출력값이 0~1 의 값이며, 이는 **확률**로 표현 가능\n",
        "\n",
        "\n",
        "$\\quad y = \\frac{1}{1 + e^{-x}}$\n",
        "\n",
        "![](https://media.geeksforgeeks.org/wp-content/uploads/20190911181329/Screenshot-2019-09-11-18.05.46.png)\n",
        "<br /><sub>출처: https://www.geeksforgeeks.org/implement-sigmoid-function-using-numpy/</sub>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q7Ywp-Pf7gC"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZcSKcAYgB9d"
      },
      "source": [
        "print(sigmoid(3))\n",
        "print(sigmoid(-3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1x6bb83gFWv"
      },
      "source": [
        "### 시그모이드 함수와 계단 함수 비교\n",
        "\n",
        "- 공통점\n",
        "  - 출력값이 0~1 내의 범위\n",
        "  - 입력값의 정도에 따라 출력값의 정도가 달라짐\n",
        "    즉, 입력이 중요하면(입력값이 크면) 큰 값을 출력\n",
        "    \n",
        "- 차이점  \n",
        " 계단함수에 비해 시그모이드 함수는\n",
        "  - 입력에 따라 출력이 연속적으로 변화\n",
        "  - 출력이 '매끄러움'  \n",
        "    이는 모든 점에서 **미분 가능**함을 의미\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67UOGQfJgDg8"
      },
      "source": [
        "plt.grid()\n",
        "x = np.arange(-5.0, 5.0, 0.01)\n",
        "y1 = sigmoid(x)\n",
        "y2 = step_function_for_numpy(x)\n",
        "plt.plot(x, y1, 'r-', x, y2, 'b--')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q3FQagJgJDs"
      },
      "source": [
        "\n",
        "### ReLU(Rectified Linear Unit)\n",
        "\n",
        "- 가장 많이 쓰이는 함수 중 하나  \n",
        "  \n",
        "  ### $ y = \\begin{cases}\n",
        "0 \\quad (x \\le 0) \\\\\n",
        "x \\quad (x > 0)\n",
        "\\end{cases} $\n",
        "\n",
        "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/Line-Plot-of-Rectified-Linear-Activation-for-Negative-and-Positive-Inputs.png)\n",
        "<br /><sub>출처: https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/</sub>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cEsh_FqgHUr"
      },
      "source": [
        "def ReLU(x):\n",
        "  return np.maximum(0, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYbYYssSgLyP"
      },
      "source": [
        "print(ReLU(5))\n",
        "print(ReLU(-3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWXjAqjngPi0"
      },
      "source": [
        "\n",
        "### 하이퍼볼릭탄젠트 함수(Hyperbolic tangent function, tanh)\n",
        "\n",
        " ### $ \\quad y = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$\n",
        "\n",
        "![](https://ww.namu.la/s/aeff20070260dc095f50d1ec74f1d4dd96bab65016ab1b01bed2145850e165e7c713734ff60047392c522e784bec9605782e4cacb2606725d782714917e2a47456d4c4a308c4b4bcc7f9a905b357556b912b404573385c42ba30e41a627dd31a)\n",
        "<br /><sub>출처: https://namu.wiki/w/%EC%8C%8D%EA%B3%A1%EC%84%A0%20%ED%95%A8%EC%88%98</sub>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF3lGXSegNZJ"
      },
      "source": [
        "def tanh(x):\n",
        "  return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6GCAu1DgSAw"
      },
      "source": [
        "print(tanh(5))\n",
        "print(tanh(-3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2bVEk3GgVDL"
      },
      "source": [
        "### Identity Function(항등 함수)\n",
        "- 회귀(Regression) 문제에서 주로 사용  \n",
        "  - 출력층의 활성화 함수로 활용\n",
        "\n",
        "- $y=x$\n",
        "\n",
        "- 입력값 그대로 출력하기 때문에 굳이 정의할 필요는 없지만  \n",
        "  신경망 중간 레이어 흐름과 통일하기 위해 사용\n",
        "\n",
        "![](https://math.info/image/394/identity_function.jpg)\n",
        "<br /><sub>출처: https://math.info/Algebra/Identity_Function/</sub>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC3M0oq_gTgY"
      },
      "source": [
        "def identity_function(x):\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V50HKDVMgXgh"
      },
      "source": [
        "print(identity_function(5))\n",
        "print(identity_function(-3))\n",
        "\n",
        "X = np.array([2, -3, 0.4])\n",
        "print(identity_function(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npL99RRugad-"
      },
      "source": [
        "### Softmax\n",
        "\n",
        "- 다중 클래스 분류에 사용(Multi Class Classification)\n",
        "- 입력값의 영향을 크게 받음  \n",
        "  입력값이 크면 출력값도 큼\n",
        "- 출력값을 확률에 대응가능\n",
        "- 출력값의 **총합은 1**\n",
        "\n",
        "- 수식  \n",
        " ### $ y_k = \\frac{exp(a_k)}{\\sum_{i=1}{exp(a_i)}}$\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*670CdxchunD-yAuUWdI7Bw.png)\n",
        "<br /><sub>출처: https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d</sub>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ku0ucpygYrE"
      },
      "source": [
        "def softmax(a):\n",
        "  exp_a = np.exp(a)\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "  y = exp_a / sum_exp_a\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HikF6Peigdew"
      },
      "source": [
        "a = np.array([0.3, 0.2, 4.0, -1.2])\n",
        "\n",
        "print(softmax(a))\n",
        "print(np.sum(softmax(a)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYIgC71lghbo"
      },
      "source": [
        "#### 소프트맥스 함수 주의점\n",
        "- 오버플로우(overflow) 문제\n",
        "- 지수함수(exponential function)을 사용하기 때문에  \n",
        "  입력값이 너무 크면 무한대(inf)가 반환됨\n",
        "\n",
        "- 개선한 수식\n",
        " ## $y_k = \\frac{exp(a_k)}{\\sum_{i=1}{exp(a_i)}} = \\frac{Cexp(a_k)}{C\\sum_{i=1}{exp(a_i)}} \\\\\n",
        "  \\quad = \\frac{exp(a_k + logC)}{\\sum_{i=1}{exp(a_i + logC)}} \\\\\n",
        "  \\quad = \\frac{exp(a_k + C')}{\\sum_{i=1}{exp(a_i + C')}}\n",
        "  $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmuXmRY8gfWc"
      },
      "source": [
        "A = np.array([1000, 9000, 1050, 500])\n",
        "print(softmax(A))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJADjg8Zgjab"
      },
      "source": [
        "def softmax(a):\n",
        "  C = np.max(a)\n",
        "  return (np.exp(a - C) / np.sum(np.exp(a - C)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQTWqn2fgk42"
      },
      "source": [
        "A = np.array([1000, 9000, 1050, 500])\n",
        "print(softmax(A))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1cWHyPbgoaH"
      },
      "source": [
        "### 활성화 함수를 비선형 함수(non-linear function)로 사용하는 이유\n",
        "- 신경망을 깊게(deep) 하기 위함\n",
        "- 만약 활성화 함수를 선형함수(linear function)으로 하게 되면 은닉층의 갯수가 여러개이더라도 의미가 없어짐\n",
        "- 만약,$\\ h(x) = cx이고, 3개의 은닉층이 존재한다면\n",
        "\\\\  \n",
        "y = h(h(h(x)))  \\\\\n",
        "\\ \\ = c*c*c*x \\\\\n",
        "\\ \\ = c^3x \\\\ $  \n",
        "이므로 결국에는 선형함수가 되어버림\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD3C4UcVgrxk"
      },
      "source": [
        "### 그 외의 활성화 함수\n",
        "- LeakyReLU\n",
        "\n",
        "### $ \\ \\ f_a(x) = \\begin{cases}\n",
        "x \\quad (x \\ge 0) \\\\\n",
        "ax \\quad (x < 0)\n",
        "\\end{cases}$\n",
        "\n",
        "![](https://i0.wp.com/knowhowspot.com/wp-content/uploads/2019/04/IMG_20190406_220045-1.jpg)\n",
        "<br /><sub>출처: https://knowhowspot.com/technology/ai-and-machine-learning/artificial-neural-network-activation-function/</sub>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BigOia-QgmcF"
      },
      "source": [
        "def LeakyReLU(x):\n",
        "  a = 0.01\n",
        "  return np.maximum(a*x, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY2YbDJ0g1Aw"
      },
      "source": [
        "x = np.array([0.5, -1.4, 3, 0, 5])\n",
        "print(LeakyReLU(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDh7qyImg4me"
      },
      "source": [
        "- ELU(Exponential Linear Units)  \n",
        "\n",
        "  $ f(\\alpha, x) = \\begin{cases}\n",
        "\\alpha \\ (e^x - 1) \\quad (x \\le 0) \\\\\n",
        "x \\qquad \\qquad (x > 0)\n",
        "\\end{cases}$  \n",
        "\n",
        "![](https://www.researchgate.net/publication/331794632/figure/fig1/AS:736888264609792@1552699261431/Exponential-Linear-Unit-activation-function-input-output-mapping-The-activation-function.jpg)\n",
        "<br /><sub>출처: https://www.researchgate.net/figure/Exponential-Linear-Unit-activation-function-input-output-mapping-The-activation-function_fig1_331794632</sub>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nImmUf9g2lV"
      },
      "source": [
        "def ELU(x):\n",
        "  alpha = 1.0\n",
        "  return (x >= 0) * x + (x < 0) * alpha * (np.exp(x) - 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kZVCKTxg_RX"
      },
      "source": [
        "print(ELU(4))\n",
        "print(ELU(-0.5))\n",
        "\n",
        "X = np.array([-2, 0.1, 4])\n",
        "print(ELU(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir3K7hhLhCf2"
      },
      "source": [
        "### 활성화 함수 참고\n",
        "\n",
        "- 일반적인 사용 순서\n",
        "  1. ELU\n",
        "  2. LeakyReLU\n",
        "  3. ReLU\n",
        "  4. tanh\n",
        "  5. sigmoid 순으로 사용\n",
        "\n",
        "- 스탠포드 강의에서 언급한 사용 순서\n",
        "  1. ReLU\n",
        "  2. ReLU Family(LeakyReLU, ELU)\n",
        "  3. sigmoid는 사용 X  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT27FzpXhJTF"
      },
      "source": [
        "## 3층 신경망 구현하기\n",
        "\n",
        "![](http://ufldl.stanford.edu/tutorial/images/Network3322.png)\n",
        "<br /><sub>출처: http://deeplearning.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/</sub>\n",
        "\n",
        "\n",
        "- 2클래스 분류\n",
        "- 입력층(Input Layer)\n",
        "  - 뉴런수: 3\n",
        "\n",
        "- 은닉층(Hidden Layers)\n",
        "  - 첫번째 은닉층\n",
        "    - 뉴런수: 3\n",
        "  - 두번째 은닉층\n",
        "    - 뉴런수: 2\n",
        "- 출력층(Output Layer)\n",
        "  - 뉴런수: 2  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2uxTBC3hQVh"
      },
      "source": [
        "### 활성화 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iEkt97EhPux"
      },
      "source": [
        "def sigmoid(X):\n",
        "  return 1 / (1 + np.exp(-X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgjFPw3DhUbO"
      },
      "source": [
        "### 레이어 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNygpfXRhS4q"
      },
      "source": [
        "X = np.array([1.0, 0.5, 0.4])\n",
        "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6], [0.3, 0.5, 0.7]])\n",
        "B1 = np.array([1, 1, 1])\n",
        "\n",
        "print(W1.shape)\n",
        "print(X.shape)\n",
        "print(B1.shape)\n",
        "\n",
        "A1 = np.dot(X, W1) + B1\n",
        "Z1 = sigmoid(A1)\n",
        "\n",
        "print(A1)\n",
        "print(Z1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gW4luZ3hVqk"
      },
      "source": [
        "\"\"\"\n",
        "두번쨰 레이어 : 3개\n",
        "  가중치 :  [0.2, 0.4, 0.6], [0.1, 0.3, 0.5], [0.4, 0.6, 0.8]\n",
        "  편향 : [1, 1, 1]\n",
        "  으로 하여 연산을 수행하고 sigmoid 활성화 함수를 적용\n",
        "\"\"\"\n",
        "\n",
        "W2 =\n",
        "B2 =\n",
        "\n",
        "print(W2.shape)\n",
        "print(B2.shape)\n",
        "\n",
        "A2 =\n",
        "Z2 =\n",
        "\n",
        "print(A2)\n",
        "print(Z2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7cgikzahYYj"
      },
      "source": [
        "\"\"\"\n",
        "세번쨰 레이어 : 3개\n",
        "  가중치 :  [0.1, 0.3], [-0.1, -0.5], [0.3, 0.5]\n",
        "  편향 : [1, 1]\n",
        "  으로 하여 연산을 수행하고 sigmoid 활성화 함수를 적용\n",
        "\"\"\"\n",
        "\n",
        "W3 =\n",
        "B3 =\n",
        "\n",
        "print(W3.shape)\n",
        "print(B3.shape)\n",
        "\n",
        "A3 =\n",
        "Z3 =\n",
        "\n",
        "print(A3)\n",
        "print(Z3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhGH6HgvhZ7r"
      },
      "source": [
        "\"\"\"\n",
        "네번쨰 레이어 : 2개\n",
        "  가중치 :  [0.1, 0.2], [0.3, 0.5]\n",
        "  편향 : [1, 1]\n",
        "  으로 하여 연산을 수행하고 sigmoid 활성화 함수를 적용\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "W4 =\n",
        "B4 =\n",
        "\n",
        "print(W4.shape)\n",
        "print(B4.shape)\n",
        "\n",
        "A4 =\n",
        "Y =\n",
        "\n",
        "print(A4)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpTPdvrbhbja"
      },
      "source": [
        "def network():\n",
        "\n",
        "  network = {}\n",
        "\n",
        "  # 첫번쨰 레이어\n",
        "  network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6], [0.3, 0.5, 0.7]])\n",
        "  network['B1'] = np.array([1, 1, 1])\n",
        "\n",
        "  # 두번째 레이어\n",
        "  network['W2'] = np.array([[0.2, 0.4, 0.6], [0.1, 0.3, 0.5], [0.4, 0.6, 0.8]])\n",
        "  network['B2'] = np.array([1, 1, 1])\n",
        "\n",
        "  # 세번째 레이어\n",
        "  network['W3'] = np.array([[0.1, 0.3], [-0.1, -0.5], [0.3, 0.5]])\n",
        "  network['B3'] = np.array([1, 1])\n",
        "\n",
        "  # 네번째 레이어\n",
        "  network['W4'] = np.array([[0.1, 0.2], [0.3, 0.5]])\n",
        "  network['B4'] = np.array([1, 1])\n",
        "\n",
        "  return network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd2lyMzhwf7Y"
      },
      "source": [
        "def forward(network, x):\n",
        "  W1, W2, W3, W4 = network['W1'], network['W2'], network['W3'], network['W4']\n",
        "  B1, B2, B3, B4 = network['B1'], network['B2'], network['B3'], network['B4']\n",
        "\n",
        "  A1 = np.dot(x, W1) + B1\n",
        "  Z1 = sigmoid(A1)\n",
        "\n",
        "  A2 = np.dot(Z1, W2) + B2\n",
        "  Z2 = sigmoid(A2)\n",
        "\n",
        "  A3 = np.dot(Z2, W3) + B3\n",
        "  Z3 = sigmoid(A3)\n",
        "\n",
        "  A4 = np.dot(Z3, W4) + B4\n",
        "  Y = sigmoid(A4)\n",
        "\n",
        "  return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_oQoRFYhf-4"
      },
      "source": [
        "### 신경망 추론 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFwxQXrShc-1"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VTYEuljiKCdV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}