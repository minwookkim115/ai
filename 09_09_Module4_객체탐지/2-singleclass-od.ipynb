{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Dataset 준비"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !pip install torchsummary -q"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import PIL\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import xml.etree.ElementTree as ET\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","import torchvision\n","from torchvision import transforms\n","import torchsummary\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["path = \"/kaggle/input/image-localization-dataset/training_images\"\n","count = 0\n","\n","for file in os.listdir(path):\n","    if file.endswith(\".jpg\"):\n","        image_path = os.path.join(path, file)\n","        xml_path = os.path.join(path, file.replace(\".jpg\", \".xml\"))\n","        if os.path.exists(xml_path) and os.path.exists(image_path) and count < 10:\n","            print(f\"image:{image_path}\\nxml:{xml_path}\\n\")\n","            count += 1"]},{"cell_type":"markdown","metadata":{},"source":["## XML 파일 읽기 및 구조\n","\n","`xml.etree.ElementTree` 모듈을 사용하면 XML 파일에서 원하는 데이터를 쉽게 추출할 수 있습니다.  \n","  \n","XML 파일은 객체 탐지를 위한 라벨링 정보를 포함하고 있습니다. 이 파일에서는 이미지의 경로, 크기, 객체의 이름, 그리고 바운딩 박스 정보(객체의 좌표) 등이 담겨 있습니다. \n","\n","```xml\n","<annotation>\n","\t<folder>single cucumber</folder>\n","\t<filename>cucumber_31.jpg</filename>\n","\t<path>C:\\Users\\Muhammed Buyukkinaci\\Downloads\\single cucumber\\cucumber_31.jpg</path>\n","\t<source>\n","\t\t<database>Unknown</database>\n","\t</source>\n","\t<size>\n","\t\t<width>227</width>\n","\t\t<height>227</height>\n","\t\t<depth>3</depth>\n","\t</size>\n","\t<segmented>0</segmented>\n","\t<object>\n","\t\t<name>cucumber</name>\n","\t\t<pose>Unspecified</pose>\n","\t\t<truncated>0</truncated>\n","\t\t<difficult>0</difficult>\n","\t\t<bndbox>\n","\t\t\t<xmin>36</xmin>\n","\t\t\t<ymin>11</ymin>\n","\t\t\t<xmax>215</xmax>\n","\t\t\t<ymax>207</ymax>\n","\t\t</bndbox>\n","\t</object>\n","</annotation>\n","```\n","\n","\n","이 중 주목해야 할 주요 요소는 다음과 같습니다.\n","\n","- `<filename>`: 이미지 파일 이름 (예: cucumber_31.jpg)\n","- `<size>`: 이미지의 크기 (width, height, depth)\n","- `<object>`: 탐지할 객체의 정보 (예: cucumber)\n","- `<bndbox>`: 객체의 좌표 정보 (xmin, ymin, xmax, ymax)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xml_path = \"/kaggle/input/image-localization-dataset/training_images/eggplant_35.xml\"\n","\n","# XML 파싱\n","tree = ET.parse(xml_path)\n","root = tree.getroot()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 파일 이름, 경로, 이미지 크기 정보 추출\n","filename =\n","image_path =\n","size = \n","width = \n","height = \n","\n","print(f\"filename: {filename}\\nimage_path: {image_path}\\nwidth: {width}\\nheight: {height}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 객체 정보 추출\n","obj =\n","label =\n","bndbox =\n","xmin =\n","ymin =\n","xmax =\n","ymax =\n","\n","print(f\"label: {label}\\nxmin: {xmin}\\nymin: {ymin}\\nxmax: {xmax}\\nymax: {ymax}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 데이터 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image_path = \"/kaggle/input/image-localization-dataset/training_images/eggplant_35.jpg\"\n","\n","image = cv2.imread(image_path)\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","plt.imshow(image)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def draw_bbox_cywh_normalized(image_path):\n","    \"\"\"\n","    이미지 경로 입력 시 xml 파일을 불러오고, bbox 정보를 추출하여 이미지+bbox를 그려주는 함수\n","    \"\"\"\n","    # Your code\n","    \n","    plt.imshow(image)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["draw_bbox_cywh_normalized(\"/kaggle/input/image-localization-dataset/training_images/eggplant_35.jpg\")"]},{"cell_type":"markdown","metadata":{},"source":["### Scaled Bounding Box로 이미지 그리기"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class2label = {\"mushroom\": 0, \"eggplant\": 1, \"cucumber\": 2}\n","label2class = {v: k for k, v in class2label.items()}\n","\n","sample_bbox = torch.tensor([xmin, ymin, xmax, ymax]).float() / torch.tensor([width, height, width, height]).float()\n","\n","sample_label = torch.tensor(class2label[label])\n","\n","print(f\"bbox: {sample_bbox}\\nlabel: {sample_label}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sample_bbox * torch.tensor([width, height, width, height]).float()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def draw_bbox(image, bbox, label):\n","    \"\"\"\n","    이미지 및 바운딩 박스를 그려주는 함수\n","    \"\"\"\n","    # 바운딩 박스 좌표를 이미지 크기에 맞게 스케일링하고 정수형으로 변환\n","    # Your code\n","    \n","    # 클래스 라벨을 타이틀로 설정\n","    # Your code"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["draw_bbox(image, sample_bbox, sample_label)"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset & DataLoader 구성"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class customDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.image_files = []\n","        self.annotation_files = []\n","        self.classes = {\"mushroom\": 0, \"eggplant\": 1, \"cucumber\": 2}\n","        \n","        # 이미지와 XML 파일을 쌍으로 추출하여 정리\n","        \n","        for file in os.listdir(self.root_dir):\n","            # Your code\n","                    \n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        # 이미지 파일과 XML 파일 경로\n","        image_path = self.image_files[idx]\n","        xml_path = self.annotation_files[idx]\n","        \n","        # 이미지 읽기\n","        image = PIL.Image.open(image_path)\n","\n","        # XML 파일에서 바운딩 박스 정보 추출\n","        # Your code\n","\n","        # 객체 정보 추출\n","        # Your code\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, bbox, label"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = customDataset(\"/kaggle/input/image-localization-dataset/training_images\", transform=transform)\n","train_dataset, val_dataset = random_split(dataset, [0.8, 0.2])\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(train_dataset), len(val_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset[0]"]},{"cell_type":"markdown","metadata":{},"source":["# 모델링"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class detector(nn.Module):\n","    def __init__(self, num_classes):\n","        super(detector, self).__init__()\n","        \n","        # CNN Layer\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n","        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        \n","        # Fully Connected Layer\n","        self.fc1 = nn.Linear(64 * 28 * 28, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        \n","        # Output layers: bbox 예측(xmin, ymin, xmax, ymax) & 분류기\n","        self.fc_bbox = nn.Linear(64, 4)  # 바운딩 박스 좌표 예측\n","        self.fc_class = nn.Linear(64, num_classes)  # 클래스 예측\n","    \n","    def forward(self, x):\n","        # Backbone\n","        # Your code\n","        \n","        # Flatten\n","        # Your code\n","        \n","        # FCL\n","        # Your code\n","        \n","        # Detection Head\n","        # Your code\n","        \n","        return bbox, class_logits"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 모델 초기화\n","num_classes = 3  # cucumber, eggplant, mushroom 3개의 클래스\n","model = detector(num_classes=num_classes).to(device)\n","torchsummary.summary(model, (3, 224, 224))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 손실 함수 설정 (MSE for bbox, CrossEntropy for class)\n","criterion_bbox = nn.MSELoss()  # 바운딩 박스 좌표 예측을 위한 MSE\n","criterion_class = nn.CrossEntropyLoss()  # 클래스 분류를 위한 CrossEntropy\n","\n","# 옵티마이저 설정\n","optimizer = optim.Adam(model.parameters(), lr=0.005)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_model(model, train_loader, val_loader, num_epochs, criterion_bbox, criterion_class, optimizer, device):\n","    model.to(device)\n","    \n","    train_losses = []\n","    val_losses = []\n","    \n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        running_bbox_loss = 0.0\n","        running_class_loss = 0.0\n","        \n","        # Train\n","        for images, bboxes, labels in tqdm(train_loader):\n","            # Your code\n","            \n","            # 배치의 손실 누적\n","            running_loss += loss_total.item()\n","            running_bbox_loss += loss_bbox.item()\n","            running_class_loss += loss_class.item()\n","        \n","        # 에포크 당 훈련 손실 계산\n","        epoch_loss = running_loss / len(train_loader)\n","        epoch_bbox_loss = running_bbox_loss / len(train_loader)\n","        epoch_class_loss = running_class_loss / len(train_loader)\n","        \n","        train_losses.append(epoch_loss)\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Train bbox Loss: {epoch_bbox_loss:.4f}, Train class Loss: {epoch_class_loss:.4f}\\nTrain Toal Loss: {epoch_loss:.4f}\")\n","        \n","        # Validation\n","        model.eval()\n","        val_running_loss = 0.0\n","        val_running_bbox_loss = 0.0\n","        val_running_class_loss = 0.0\n","        \n","        with torch.no_grad():\n","            for images, bboxes, labels in val_loader:\n","                # Your code\n","                \n","                val_running_loss += loss_total.item()\n","                val_running_bbox_loss += loss_bbox.item()\n","                val_running_class_loss += loss_class.item()\n","        \n","        # 에포크 당 검증 손실 계산\n","        val_loss = val_running_loss / len(val_loader)\n","        val_bbox_loss = val_running_bbox_loss / len(val_loader)\n","        val_class_loss = val_running_class_loss / len(val_loader)\n","\n","        val_losses.append(val_loss)\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Val bbox Loss: {val_bbox_loss:.4f}, Val class Loss: {val_class_loss:.4f}\\nVal Total Loss: {val_loss:.4f}\")\n","    \n","    return train_losses, val_losses"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["epochs = 30\n","train_losses, val_losses = train_model(model, train_loader, val_loader, epochs, criterion_bbox, criterion_class, optimizer, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.plot(train_losses, label='train loss')\n","plt.plot(val_losses, label='val loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.ylim([0, 1])\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def predict(model, image):\n","    model.eval()\n","    image = image.to(device)\n","    output = model(image.unsqueeze(0))\n","    print(output)\n","    bbox = output[0][0].detach().cpu()\n","    class_logits = output[1][0].detach().cpu()\n","    class_prob = F.softmax(class_logits, dim=-1)\n","    return bbox, class_prob"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["bbox, class_prob = predict(model, val_dataset[0][0])\n","bbox, class_prob"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xx = val_dataset[0][0].detach().cpu().numpy().transpose(1, 2, 0)\n","# denormalize\n","xx = ((xx * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))*255).astype(np.uint8)\n","\n","plt.imshow(xx)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def draw_prediction(image, bbox, class_prob):\n","    image = image.detach().cpu().numpy().transpose(1, 2, 0)\n","    image = ((image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))*255).astype(np.uint8)\n","\n","    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","    class_prob = class_prob.argmax(axis=-1)\n","    print(bbox, class_prob)\n","    predicted_img = draw_bbox(image, bbox, class_prob)\n","    return predicted_img"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["draw_prediction(val_dataset[0][0], bbox, class_prob)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":50025,"sourceId":91366,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
