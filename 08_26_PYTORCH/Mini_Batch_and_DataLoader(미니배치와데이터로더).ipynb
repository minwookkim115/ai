{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA LOADER\n",
    "- 미니 배치 학습, 데이터 셔플, 병렬처리(GPU 여러개 학습)까지 수행 가능\n",
    "- GPU, SDD(HDD), RAM 간의 병목현상을 예방해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset # 텐서데이터셋, 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  90], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x_train, y_train) # 정답을 짝지어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[89., 91., 90.],\n",
      "        [93., 88., 93.]]), tensor([[180.],\n",
      "        [185.]])]\n",
      "1 [tensor([[ 73.,  66.,  70.],\n",
      "        [ 96.,  98., 100.]]), tensor([[142.],\n",
      "        [196.]])]\n",
      "2 [tensor([[73., 80., 75.]]), tensor([[152.]])]\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader):\n",
    "    print(i, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionModel(\n",
      "  (linear1): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (linear2): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(3, 3)\n",
    "        self.linear2 = nn.Linear(3, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "model = LinearRegressionModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Batch 1/3 Cost: 26669.953125\n",
      "Epoch    0/1000 Batch 2/3 Cost: 46197680.000000\n",
      "Epoch    0/1000 Batch 3/3 Cost: 36614.152344\n",
      "Epoch   50/1000 Batch 1/3 Cost: 21608.093750\n",
      "Epoch   50/1000 Batch 2/3 Cost: 24748.507812\n",
      "Epoch   50/1000 Batch 3/3 Cost: 26119.384766\n",
      "Epoch  100/1000 Batch 1/3 Cost: 11589.011719\n",
      "Epoch  100/1000 Batch 2/3 Cost: 20434.822266\n",
      "Epoch  100/1000 Batch 3/3 Cost: 24425.197266\n",
      "Epoch  150/1000 Batch 1/3 Cost: 13068.722656\n",
      "Epoch  150/1000 Batch 2/3 Cost: 15499.833008\n",
      "Epoch  150/1000 Batch 3/3 Cost: 8807.588867\n",
      "Epoch  200/1000 Batch 1/3 Cost: 13137.139648\n",
      "Epoch  200/1000 Batch 2/3 Cost: 8512.555664\n",
      "Epoch  200/1000 Batch 3/3 Cost: 6104.886719\n",
      "Epoch  250/1000 Batch 1/3 Cost: 10254.728516\n",
      "Epoch  250/1000 Batch 2/3 Cost: 6889.776367\n",
      "Epoch  250/1000 Batch 3/3 Cost: 2999.406494\n",
      "Epoch  300/1000 Batch 1/3 Cost: 5135.188477\n",
      "Epoch  300/1000 Batch 2/3 Cost: 8014.404297\n",
      "Epoch  300/1000 Batch 3/3 Cost: 1855.531006\n",
      "Epoch  350/1000 Batch 1/3 Cost: 3468.627930\n",
      "Epoch  350/1000 Batch 2/3 Cost: 4346.984375\n",
      "Epoch  350/1000 Batch 3/3 Cost: 5789.616699\n",
      "Epoch  400/1000 Batch 1/3 Cost: 907.455139\n",
      "Epoch  400/1000 Batch 2/3 Cost: 5059.158691\n",
      "Epoch  400/1000 Batch 3/3 Cost: 4570.538574\n",
      "Epoch  450/1000 Batch 1/3 Cost: 1677.402222\n",
      "Epoch  450/1000 Batch 2/3 Cost: 2909.165527\n",
      "Epoch  450/1000 Batch 3/3 Cost: 3623.645508\n",
      "Epoch  500/1000 Batch 1/3 Cost: 1502.349854\n",
      "Epoch  500/1000 Batch 2/3 Cost: 3280.968262\n",
      "Epoch  500/1000 Batch 3/3 Cost: 426.901947\n",
      "Epoch  550/1000 Batch 1/3 Cost: 1863.687866\n",
      "Epoch  550/1000 Batch 2/3 Cost: 1170.182983\n",
      "Epoch  550/1000 Batch 3/3 Cost: 1855.920776\n",
      "Epoch  600/1000 Batch 1/3 Cost: 789.867615\n",
      "Epoch  600/1000 Batch 2/3 Cost: 1476.750854\n",
      "Epoch  600/1000 Batch 3/3 Cost: 1876.422119\n",
      "Epoch  650/1000 Batch 1/3 Cost: 606.202148\n",
      "Epoch  650/1000 Batch 2/3 Cost: 2031.309082\n",
      "Epoch  650/1000 Batch 3/3 Cost: 14.527827\n",
      "Epoch  700/1000 Batch 1/3 Cost: 29.756359\n",
      "Epoch  700/1000 Batch 2/3 Cost: 1116.557373\n",
      "Epoch  700/1000 Batch 3/3 Cost: 2189.112061\n",
      "Epoch  750/1000 Batch 1/3 Cost: 1346.221558\n",
      "Epoch  750/1000 Batch 2/3 Cost: 537.038025\n",
      "Epoch  750/1000 Batch 3/3 Cost: 104.938667\n",
      "Epoch  800/1000 Batch 1/3 Cost: 1297.767944\n",
      "Epoch  800/1000 Batch 2/3 Cost: 397.803894\n",
      "Epoch  800/1000 Batch 3/3 Cost: 8.640385\n",
      "Epoch  850/1000 Batch 1/3 Cost: 274.393921\n",
      "Epoch  850/1000 Batch 2/3 Cost: 1142.151367\n",
      "Epoch  850/1000 Batch 3/3 Cost: 230.680084\n",
      "Epoch  900/1000 Batch 1/3 Cost: 168.339386\n",
      "Epoch  900/1000 Batch 2/3 Cost: 1024.992310\n",
      "Epoch  900/1000 Batch 3/3 Cost: 441.335876\n",
      "Epoch  950/1000 Batch 1/3 Cost: 470.665161\n",
      "Epoch  950/1000 Batch 2/3 Cost: 814.650146\n",
      "Epoch  950/1000 Batch 3/3 Cost: 74.466713\n",
      "Epoch 1000/1000 Batch 1/3 Cost: 838.795654\n",
      "Epoch 1000/1000 Batch 2/3 Cost: 252.813934\n",
      "Epoch 1000/1000 Batch 3/3 Cost: 321.183197\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=5e-4)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        x, y_true = batch\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = F.mse_loss(y_pred, y_true)\n",
    "\n",
    "        # if idx == 0:\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "                  print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "          epoch, epochs, idx + 1, len(dataloader), loss.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 커스텀 데이터셋으로 선형회귀 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 상속\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self):\n",
    "    self.x_data = [[73, 80, 75],\n",
    "                   [93, 88, 93],\n",
    "                   [89, 91, 90],\n",
    "                   [96, 98, 100],\n",
    "                   [73, 66, 70]]\n",
    "    self.y_data = [[152], [185], [180], [196], [142]]\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "  def __getitem__(self, idx): \n",
    "    x = torch.FloatTensor(self.x_data[idx])\n",
    "    y = torch.FloatTensor(self.y_data[idx])\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomDataset at 0x7f223e175430>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CustomDataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([73., 80., 75.]), tensor([152.]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 768.688354\n",
      "Epoch    0/20 Batch 2/3 Cost: 305.888428\n",
      "Epoch    0/20 Batch 3/3 Cost: 299.285339\n",
      "Epoch    1/20 Batch 1/3 Cost: 305.888428\n",
      "Epoch    1/20 Batch 2/3 Cost: 704.083252\n",
      "Epoch    1/20 Batch 3/3 Cost: 428.495544\n",
      "Epoch    2/20 Batch 1/3 Cost: 305.888428\n",
      "Epoch    2/20 Batch 2/3 Cost: 704.083252\n",
      "Epoch    2/20 Batch 3/3 Cost: 428.495544\n",
      "Epoch    3/20 Batch 1/3 Cost: 803.082520\n",
      "Epoch    3/20 Batch 2/3 Cost: 363.890442\n",
      "Epoch    3/20 Batch 3/3 Cost: 114.492874\n",
      "Epoch    4/20 Batch 1/3 Cost: 206.889099\n",
      "Epoch    4/20 Batch 2/3 Cost: 803.082520\n",
      "Epoch    4/20 Batch 3/3 Cost: 428.495544\n",
      "Epoch    5/20 Batch 1/3 Cost: 398.284668\n",
      "Epoch    5/20 Batch 2/3 Cost: 271.494202\n",
      "Epoch    5/20 Batch 3/3 Cost: 1108.881104\n",
      "Epoch    6/20 Batch 1/3 Cost: 462.889771\n",
      "Epoch    6/20 Batch 2/3 Cost: 206.889099\n",
      "Epoch    6/20 Batch 3/3 Cost: 1108.881104\n",
      "Epoch    7/20 Batch 1/3 Cost: 271.494202\n",
      "Epoch    7/20 Batch 2/3 Cost: 398.284668\n",
      "Epoch    7/20 Batch 3/3 Cost: 1108.881104\n",
      "Epoch    8/20 Batch 1/3 Cost: 768.688354\n",
      "Epoch    8/20 Batch 2/3 Cost: 305.888428\n",
      "Epoch    8/20 Batch 3/3 Cost: 299.285339\n",
      "Epoch    9/20 Batch 1/3 Cost: 398.284668\n",
      "Epoch    9/20 Batch 2/3 Cost: 271.494202\n",
      "Epoch    9/20 Batch 3/3 Cost: 1108.881104\n",
      "Epoch   10/20 Batch 1/3 Cost: 462.889771\n",
      "Epoch   10/20 Batch 2/3 Cost: 704.083252\n",
      "Epoch   10/20 Batch 3/3 Cost: 114.492874\n",
      "Epoch   11/20 Batch 1/3 Cost: 611.687012\n",
      "Epoch   11/20 Batch 2/3 Cost: 462.889771\n",
      "Epoch   11/20 Batch 3/3 Cost: 299.285339\n",
      "Epoch   12/20 Batch 1/3 Cost: 271.494202\n",
      "Epoch   12/20 Batch 2/3 Cost: 398.284668\n",
      "Epoch   12/20 Batch 3/3 Cost: 1108.881104\n",
      "Epoch   13/20 Batch 1/3 Cost: 271.494202\n",
      "Epoch   13/20 Batch 2/3 Cost: 398.284668\n",
      "Epoch   13/20 Batch 3/3 Cost: 1108.881104\n",
      "Epoch   14/20 Batch 1/3 Cost: 271.494202\n",
      "Epoch   14/20 Batch 2/3 Cost: 704.083252\n",
      "Epoch   14/20 Batch 3/3 Cost: 497.283997\n",
      "Epoch   15/20 Batch 1/3 Cost: 704.083252\n",
      "Epoch   15/20 Batch 2/3 Cost: 462.889771\n",
      "Epoch   15/20 Batch 3/3 Cost: 114.492874\n",
      "Epoch   16/20 Batch 1/3 Cost: 206.889099\n",
      "Epoch   16/20 Batch 2/3 Cost: 803.082520\n",
      "Epoch   16/20 Batch 3/3 Cost: 428.495544\n",
      "Epoch   17/20 Batch 1/3 Cost: 803.082520\n",
      "Epoch   17/20 Batch 2/3 Cost: 206.889099\n",
      "Epoch   17/20 Batch 3/3 Cost: 428.495544\n",
      "Epoch   18/20 Batch 1/3 Cost: 363.890442\n",
      "Epoch   18/20 Batch 2/3 Cost: 803.082520\n",
      "Epoch   18/20 Batch 3/3 Cost: 114.492874\n",
      "Epoch   19/20 Batch 1/3 Cost: 398.284668\n",
      "Epoch   19/20 Batch 2/3 Cost: 271.494202\n",
      "Epoch   19/20 Batch 3/3 Cost: 1108.881104\n",
      "Epoch   20/20 Batch 1/3 Cost: 462.889771\n",
      "Epoch   20/20 Batch 2/3 Cost: 611.687012\n",
      "Epoch   20/20 Batch 3/3 Cost: 299.285339\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "  for batch_idx, samples in enumerate(dataloader):\n",
    "    # print(batch_idx)\n",
    "    # print(samples)\n",
    "    x_train, y_train = samples\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 계산\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
    "        cost.item()\n",
    "        ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
